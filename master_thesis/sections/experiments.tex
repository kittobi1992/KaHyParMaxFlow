In this Section, we evaluate the performance of our flow-based refinement framework. 
First, we show the effects of our sparsification techniques of the Lawler-Network 
\cite{lawler1973} on the running time of maximum flow algorithms.
Afterwards, we analyze how the maximum
flow problem size influences the solution quality of different configurations of
our framework. Finally, we compare the new version of \emph{KaHyPar} with
\emph{Max-Flow-Min-Cut} computations with
state-of-the-art hypergraph partitioners.


\subsection{Instances}

Our full benchmark set consists of $488$ hypergraphs from three different 
application areas. For VLSI design, we use instances from
the \emph{ISPD98 VLSI Circuit Benchmark Suite} (\ISPD) \cite{alpert1998ispd98} and add more recent
instances of the \emph{DAC 2012 Routability-Driven Placement Contest} (\DAC) \cite{viswanathan2012dac}.
We interpret the Sparse Matrix instances of the \emph{Florida Sparse Matrix 
Collection} (\SPM) \cite{davis2011university} as hypergraphs using the row-net model \cite{catalyurek1999hypergraph}.
The rows of each matrix are treated as hyperedges and the columns are the vertices of
the hypergraph. Our last benchmark type are SAT formulas of the \emph{International SAT
Competition 2014} \cite{belov2014application}. A common representation of a SAT formula 
as hypergraph is to define the literals as vertices and each clause as a net (\Literal) \cite{papa2007hypergraph}.
Mann and Papp \cite{mann2014formula} suggested two other hypergraph representations, 
called \Primal~and \Dual. The \Primal~representation treats each variable
as vertex and each clause as hyperedge. The \Dual~representation treats each clause as
vertex and the variables induce nets containing all clauses where the corresponding
variable occurs. A summary of the different instance types is presented in
Table \ref{tbl:full_benchmark_set}. \\
We divide our full benchmark set into two smaller subsets. Our \emph{parameter tuning}
benchmark set consists of $25$ hypergraphs (see Table \ref{tbl:parameter_tunning_set}), $5$ of each instance type (except \DAC). Additionally,
we choose a benchmark subset of $165$ instances (see Table \ref{tbl:benchmark_subset}). If we test the quality of our partitioner, 
we partition each hypergraph into $k \in \{2,4,8,16,32,64,128\}$ blocks and use $10$ different
\emph{seeds} for each $k$ and an imbalance of $\epsilon = 3\%$.

\subsection{System and Methodology}
\label{sec:methodology}

Our experiments run on a single core of a machine consisting of two \emph{Intel Xeon E5-
2670 Octa-Core} processors clocked at $2.6$ GHz. The machine has $64$ GB main memory,
$20$ MB L$3$- and $8\times256$ KB L$2$-Cache. The code is written in C++ and compiled using
\lstinline{g++-5.2} with flags \lstinline{-O3 -mtune=nactive -march=native}. We refer to
our new implementation of \emph{KaHyPar} with \emph{(M)ax-(F)low-Min-Cut} computations 
as \KaHyPar{MF} and the latest configuration with \emph{(C)ommunity-(A)ware} coarsening as
\KaHyPar{CA}. \\
We compare \KaHyPar{MF} with the state-of-the-art hypergraph partitioners hMetis
\cite{karypis1999multilevel,karypis2000multilevel} and PaToH \cite{catalyurek1999hypergraph}.
hMetis provides a direct $k$-way (\hMetis{K}) and recursive bisection (\hMetis{R}) implementation.
Further, we use the default configuration (\PaToH{D}) and quality preset (\PaToH{Q}) of
PaToH. We configure hMetis to optimize the \emph{sum-of-external-degrees}-metric
(SOED) and calculate $(\lambda-1)(\Pi) = \text{SOED}(\Pi) - \text{cut}(\Pi)$. This is also
suggested by the authors of hMetis \cite{karypis2000multilevel}. Additionally, we have
to adapt the imbalance definition of \hMetis{R}. An imbalance value of $5$ means that the weight
of each bisected block is allowed to be between $0.45 \cdot c(V)$ and $0.55 \cdot c(V)$.
To ensure that \hMetis{R} produces a valid $\epsilon$-balanced partition after $\log_2(k)$
bisections we have to adapt $\epsilon$ to
\[\epsilon' = 100 \cdot \Bigg( \left( (1 + \epsilon) \frac{\lceil \frac{c(V)}{k} \rceil}{c(V)} \right)^{\frac{1}{\log_2(k)}} - 0.5 \Bigg) \text{.}\]
If we evaluate the performance of a hypergraph partitioner,
we first summarize the results by calculating the arithmetic mean (or minimum) of a specific metric
for the diffrent \emph{seeds} of a hypergraph partitioned into $k$ blocks. 
Afterwards, we calculate the \emph{geometric mean} of 
all instances to give each instance comparable influence on the final result. 
To compare the performance of different hypergraph partitioners in more detail
we use performance plots introduced in \cite{schlag2016k}.
In the following, we call a $k$-way partition of a hypergraph an \emph{instance}.
For each algorithm we determine the instance with the 
best quality (of the $10$ different \emph{seeds}). Each color in the plot corresponds to
one algorithm. The $x$-axis represents the number of instances and the $y$-axis represents the quality ratio
produced by an algorithm for an instance relative to the partition of the best algorithm. 
For example, partitioner $P_1$ produces a partition for an instance $X$ with
quality $100$ and partitioner $P_2$ produces a partition for the same instance of quality $105$.
Then, the $y$-value for instance $X$ of partitioner $P_2$ is $1 - \frac{100}{105} \approx 0.048$ and
for partitioner $P_1$ is $1 - \frac{100}{100} = 0$, which means that the partition of partitioner $P_2$
for instance $X$ is $\approx 4.8\%$ worse than the best partition produced for instance $X$.
 A value of zero indicates that the algorithm
produced the best partition. A point close to one indicates that the partition produced by the 
corresponding partitioner was considerably worse than the partition produced by the best
algorithm. Before we add the points to the grid, we sort them in decreasing order 
according to the $y$-values. An algorithm is considered to outperform another algorithm if its 
corresponding ratio values are below those of the other algorithm. A point with an $y$-value
greater than one corresponds to an infeasible solution that violated the balanced constraint.

\subsection{Flow Algorithms and Networks}
\label{sec:exp_flow_network}

In the first experiment, we evaluate the effect of our sparsification techniques
on the performance of the maximum flow algorithms \EdmondKarp, \GoldbergTarjan, \BoykovKolmogorov~and \IBFS. 
We refer to the Lawler-Network as $\ExpLawler$, which is our baseline flow network. In
Section \ref{sec:opt_flow_network} we present several techniques to reduce the number
of nodes and edges of $\ExpLawler$. $\ExpNodeDegree$ represents our flow network in which
we remove all hypernodes with a degree smaller or equal to $3$. The network $\ExpEdgeSize$ models
each hyperedge of size $2$ as undirected graph edge between the corresponding pins. Finally,
$\ExpHybrid$ combines both networks. \\
We evaluate the performance of our maximum flow algorithms on flow problems with
$|V'| \in \{500,1000,5000,10000,25000\}$ hypernodes. The instances are generated by executing
\emph{KaHyPar} on our benchmark subset (see Table \ref{tbl:benchmark_subset}) for $k = 2$ and five different 
seeds. After an instance is bipartitioned, we generate flow problems
with the above-mentioned sizes and execute each possible combination of flow algorithm and
flow network on it. \\
\autoref{fig:node_edge_distribution}~shows the average number of nodes and edges
of the resulting flow networks for flow problems with $25000$ hypernodes. As expected,
$\ExpNodeDegree$ reduces the number of nodes more significantly on instances with low
degree hypernodes (\Dual) and $\ExpEdgeSize$ on instances with small hyperedges
(\Primal~and \Literal). Further, $\ExpHybrid$ combines the advantages of both networks
and reduces the number of nodes and edges of nearly each benchmark type by at least a factor of $2$,
except on \SPM~instances. If we compare the sizes of the resulting flow problems, we can observe
that instances with a high density ($d = \frac{|E|}{|V|}$), like \Primal~or \Literal, yields large flow problem 
and instances with a low density yield small flow problems (see \Dual~instances). \\
\begin{figure}[ht!]
\centering
\input{experiments/flow_network/node_edge_distribution.tex} %
\caption{Comparison of the number of nodes and edges induced by flow problems 
         of size $|V'| = 25000$ on our flow networks for different benchmark types.
         The red dashed lines indicates $25000$ nodes.}
\label{fig:node_edge_distribution} 
\end{figure} 
In \autoref{fig:max_flow_network_algo}~we compare the performance of our maximum flow algorithms
on different flow networks. A bar in the plot indicates the speed-up of the corresponding algorithm
executed on $\ExpNodeDegree$, $\ExpEdgeSize$ or $\ExpHybrid$ relative to the execution on $\ExpLawler$.
The main observation is that the speed-ups are nearly proportional to the reduction of the number
of nodes and edges of the corresponding flow network. For example, $\ExpHybrid$ reduces the size
of the flow problems of nearly each benchmark type by at least factor of $2$ compared to $\ExpLawler$. Consequently,
the speed-ups of our maximum flow algorithms on $\ExpHybrid$ are nearly up to a factor of $2$ on each
benchmark type. Our \GoldbergTarjan~implementation benefits most from our sparsification 
techniques. The algorithm is around $3$ to $4$ times faster on $\ExpHybrid$ than on 
$\ExpLawler$. All algorithms perform best on $\ExpHybrid$. In conclusion, our
sparsification techniques not only reduce the size of the flow problems, they also
improve the running time of several maximum flow algorithms significantly.\\
\begin{figure}
\centering
\input{experiments/flow_network/speed_up_flow_network.tex} %
\caption{Speed-ups of the flow algorithms on different flow networks relative to execution on
         $\ExpLawler$ for different problem sizes and types. The red resp. blue dashed line 
         indicate a speed-up of $1$ resp. $2$.}
\label{fig:max_flow_network_algo}
\end{figure} 
In \autoref{tbl:flow_algo_network_summary}, we compare the absolute running times of the 
algorithms on our fastest flow network $\ExpHybrid$. The \IBFS~algorithm works best on
large instances ($|V'| > 1000$). For smaller benchmarks ($|V'| \le 1000$) 
\BoykovKolmogorov~and \EdmondKarp~are faster than the \IBFS~algorithm. 
However, we are currently not able to use the \IBFS~algorithm
in our \emph{flow}-based local search algorithm. The data structure of the algorithm
is not optimized for multiple executions on different flow networks, because the allocated 
memory of the old flow network is not deleted if we build a new flow network. 
However, we currently work on a reimplementation
of the algorithm such that it can be used. Therefore, we use the \BoykovKolmogorov~maximum 
flow algorithm in combination with our flow network $\ExpHybrid$ in the following experiments.
\begin{table}
\renewcommand{\arraystretch}{1.15} 
\footnotesize
\centering
\begin{tabular}{r|S[table-number-alignment = center,table-column-width=2.5cm]|
                  S[table-number-alignment = center]|
                  S[table-number-alignment = center]|
                  S[table-number-alignment = center]} 
\toprule
\quad\quad & \multicolumn{1}{c|}{\IBFS} & \BoykovKolmogorov & \GoldbergTarjan & \EdmondKarp \\
$|V'|$ &  $t[ms]$ & $t[\%]$ & $t[\%]$ & $t[\%]$ 
\\\midrule% 
\csname @@input\endcsname experiments/flow_network/flow_network_max_flow_summary_table.tex 
\bottomrule
\end{tabular}
\caption{Average running times of our maximum flow algorithms on flow network $\ExpHybrid$.
         Note, all values in the table are in percentage relative to the running time
         of the \IBFS~algorithm. In each line the fastest variant is marked bold.}
\label{tbl:flow_algo_network_summary}
\end{table}

\subsection{Configuring direct $k$-way Flow-based Refinement}
\label{sec:flow_configuration}

In this section, we analyze the quality of our $k$-way flow-based refinement algorithm with
different configurations on our parameter tuning benchmark subset.
There are several configurations and tuning parameters that we have to evaluate:
\begin{itemize}
\item \emph{Max-(F)low-Min-Cut} computations as refinement algorithm
\item \emph{Adaptive Flow Iteration} parameter $\alpha'$ (see Section \ref{sec:adaptive_flow_iterations})
\item \emph{(M)ost Balanced Minimum Cut} heuristic (see Section \ref{sec:mbmc_hypergraphs})
\item Combining \emph{Max-(F)low-Min-Cut} computations with \emph{(FM)} refinement
\end{itemize}
In the following, we denote a configuration for example with \FlowVariant{+}{-}{-} that indicates
which heuristic resp. technique is enabled $(+)$ or disabled $(-)$. The meaning of the 
abbreviations is explained in the enumeration above (see letters inside parentheses). We evaluate
each configuration for $k \in \{2,4,8,16,32,64,128\}$, $\alpha' \in \{1,2,4,8,16\}$
and $10$ different seeds and an imbalance of $\epsilon = 3\%$.  We execute a \emph{flow}-based refinement
on each level $i$ with $i = 2^j$ ($j \in \mathbb{N}_+$).
Additionally, we add configuration \FlowVariant{+}{+}{+} with \emph{flow execution policy} 
$i = 128j$ ($j \in \mathbb{N}_+$). This configuration has a prohibitively large running time, 
but it is used as an upper bound for the quality achievable with \emph{Max-Flow-Min-Cut} 
computations in combination with \emph{FM} refinement. We refer to this variant as \Constant{128}\footnote{Due to the large running time this configuration uses all three speed-up heuristics}. 
We use \KaHyPar{CA} as reference \cite{heuer2017improving} and refer to it 
as \FlowVariant{-}{-}{+}. \\

\begin{table}[ht]
\renewcommand{\arraystretch}{1.15}
\centering
\begin{tabular}{|r||*{2}{S[table-number-alignment = center]|}|
                    *{2}{S[table-number-alignment = center]|}|
                    *{2}{S[table-number-alignment = center]|}|
                    *{2}{S[table-number-alignment = center]|}}
\toprule
 Config. & \multicolumn{2}{c||}{\FlowVariant{+}{-}{-}} & \multicolumn{2}{c||}{\FlowVariant{+}{+}{-}}  & \multicolumn{2}{c||}{\FlowVariant{+}{+}{+}} & \multicolumn{2}{c|}{\Constant{128}} \\
\midrule
$\alpha'$ & Avg $[\%]$ & $t[s]$ & Avg $[\%]$ & $t[s]$ & Avg $[\%]$ & $t[s]$ & Avg $[\%]$ & $t[s]$ \\
\midrule%
\csname @@input\endcsname experiments/flow_alpha/flow_alpha_table.tex 
\bottomrule 
\end{tabular}
\caption{ Table contains results for different configurations of our flow-based refinement
          framework for increasing $\alpha'$. The quality in column \emph{Avg.} is relative
          to our baseline configuration \FlowVariant{-}{-}{+}. }
\label{tbl:alpha_exp}
\end{table}

The results are summarized in \autoref{tbl:alpha_exp}. The values
in column \emph{Avg} are improvements
relative to our baseline configuration \FlowVariant{-}{-}{+}. The running
time are absolute values in seconds. The first observation is that flows
only are not strong enough to outperform the
\emph{FM} heuristic. Our strongest configuration with $\alpha' = 16$
is $0.2\%$ worse than the \emph{FM} baseline. 
Enabling the \emph{Most Balanced Minimum Cut} heuristic significantly improves the
quality compared to the configuration \FlowVariant{+}{-}{-}.
The quality improvements are more significant for large
$\alpha'$. The larger the flow problem size, the larger is the number of different minimum 
$(S,T)$-cutsets and this increases the possibility to find a feasible solution that respects the 
balance constraint. Also it outperforms our baseline \emph{FM} 
configuration for $\alpha' = 16$ by $1.75\%$.
If we enable \emph{FM} refinement, we improve the solution
quality by $2.21\%$ (for $\alpha' = 16$). Also, the running time of this variant is faster
than all previous flow configurations because we transfer more work to the \emph{FM} refinement.
Consequently, a block becomes \emph{inactive} faster during the \emph{active block 
scheduling} algorithm and this decreases the number of rounds of complete pairwise 
flow-based refinements. 
Finally, \Constant{128} gives us an upper bound of the quality
achievable with a combination of \emph{flow}-based and \emph{FM} refinement. Flows are executed 
in each $128$th level of the multilevel hierarchy. The quality is $2.69\%$ better than our
baseline configuration, but roughly $50$ times slower. Compared to \FlowVariant{+}{+}{+} for 
$\alpha = 16$, \Constant{128} is only $0.48\%$ better and around roughly $10$ times slower.\\
Our best configuration is \FlowVariant{+}{+}{+} with $\alpha' = 16$. 
It is also the most effective one (see Effectiveness Test in Appendix \ref{appendix:effectiveness_test}). 
For further experiments, we refer to this variant as \KaHyPar{MF}. \\
At the end of Section \ref{sec:source_and_sink}, we compare our source and sink set modeling
approach (\textsc{M2}) with the one of Sanders and Schulz \cite{sanders2011engineering} (\textsc{M1}). The main result is
that our approach should theoretically yield to better minimum cuts, because we do not restrict
all hypernodes contained in a non-cut hyperedge, which is partially contained in the flow problem,
to stay in the same block after a \emph{Max-Flow-Min-Cut} computation. In \autoref{tbl:alpha_comparison_exp}
we compare the two modeling approaches in practice. The quality of our \emph{flow}-based
configurations without the \emph{FM} algorithm are up to $5\%$ to $10\%$ better for 
$\alpha' \le 4$. For $\alpha' > 4$ the improvement is around $1.5\%$ to $2.5\%$. For small
$\alpha'$ most of the hypernodes of the flow problem are incident to a non-cut hyperedge partially
contained in the flow problem. Therefore, \textsc{M1} restricts them to stay in the same block
after a \emph{Max-Flow-Min-Cut} computation. \textsc{M2} allows them to change its block, if 
it yields a smaller minimum cut.

\begin{table}
\renewcommand{\arraystretch}{1.15}
\centering
\begin{tabular}{|r||*{2}{S[table-number-alignment = center]|}|
                    *{2}{S[table-number-alignment = center]|}|
                    *{2}{S[table-number-alignment = center]|}|}
\toprule
 Config. & \multicolumn{2}{c||}{\FlowVariant{+}{-}{-}} & \multicolumn{2}{c||}{\FlowVariant{+}{+}{-}}  & \multicolumn{2}{c|}{\FlowVariant{+}{+}{+}} \\
\midrule
$\alpha'$ & \footnotesize{\textsc{M1} - Avg $[\%]$} & \footnotesize{\textsc{M2} - Avg $[\%]$} & \footnotesize{\textsc{M1} - Avg $[\%]$} & \footnotesize{\textsc{M2} - Avg $[\%]$} & \footnotesize{\textsc{M1} - Avg $[\%]$} & \footnotesize{\textsc{M2} - Avg $[\%]$}  \\
\midrule%
\csname @@input\endcsname experiments/flow_alpha/flow_alpha_modeling_comparison_table.tex
\bottomrule
\end{tabular}
\caption{ Comparison on quality of our framework with different source and sink set
          modeling approaches. \textsc{M1} represents the approach of Sanders and Schulz
          \cite{sanders2011engineering} and \textsc{M2} is our new variant proposed 
          in Section \ref{sec:source_and_sink}.  }
\label{tbl:alpha_comparison_exp}
\end{table}


\subsection{Speed-Up Heuristics}
\label{sec:speed_up}

At the end of Section \ref{sec:integration_kahypar}, we presented several heuristics
which help to prevent \emph{unpromising} flow executions during active block scheduling ((R1)-(R3)).
The main assumption is that only a minority of \emph{Max-Flow-Min-Cut} computations
lead to an improvement. To verify this assumption, 
we execute \KaHyPar{MF} in combination with different speed-up heuristics 
on our benchmark subset (see Table \ref{tbl:benchmark_subset}). \\
Table \ref{tbl:heuristics} summarizes the results of the experiment. The indices of the 
different variants of \KaHyPar{MF} describe which speed-up heuristic is enabled.
On average, enabling all speed-up heuristics worsen the quality of \KaHyPar{MF} only by 
$0.07\%$. On the other hand, the framework is significantly faster 
by a factor of $2$. In its final configuration, \KaHyParConfig{MF}{R1,R2,R3} computes 
partitions with $2.41\%$ better quality than \KaHyPar{CA}, while only
incurring a slowdown of a factor of $2$. In the following, we denote our final 
configuration \KaHyParConfig{MF}{R1,R2,R3} as \KaHyPar{MF}. 

\begin{table}[ht]
\renewcommand{\arraystretch}{1.15}
\centering
\begin{tabular}{l|*{4}{S[table-number-alignment = center,table-column-width=2cm]}}
\toprule
Variant & \multicolumn{1}{c}{Avg $[\%]$} & \multicolumn{1}{c}{Min $[\%]$} & \multicolumn{1}{c}{$t_{\text{flow}}[s]$} & \multicolumn{1}{c}{$t[s]$} \\ 
\midrule%
\csname @@input\endcsname experiments/speed_up_heuristics/heuristic_table.tex 
\bottomrule
\end{tabular} 
\caption{Results of our flow-based refinement framework with different speedup heuristics.}
\label{tbl:heuristics}
\end{table} 

\subsection{Comparison with other Hypergraph Partitioners}
\label{sec:final_comparison}

Finally, we compare our new approach \KaHyPar{MF} with different state-of-the-art hypergraph
partitioners on the full benchmark set. We excluded $200$ instances of $3416$ either because 
\PaToH{Q} could not allocate enough memory or other partitioners did not finish in time. The
excluded instances are shown in Table \ref{tbl:excluded}. \\
\autoref{fig:final_flow}~summarizes the results of the experiment. \KaHyPar{MF}
produces the best partitions on $72.9\%$ of all benchmark instances. It is followed by
\hMetis{R} ($12.3\%$), \hMetis{K} ($10.3\%$), \KaHyPar{CA} ($1.3\%$), 
\PaToH{Q} ($1.8\%$) and \PaToH{D} ($1.4\%$). \KaHyPar{MF} improves the quality of 
\KaHyPar{CA} by $2.49\%$ (see \autoref{tbl:full_quality}). Comparing \KaHyPar{MF} 
with each partitioner individually, \KaHyPar{MF} produces better partitions than \KaHyPar{CA},
\hMetis{R}, \hMetis{K}, \PaToH{Q}, \PaToH{Q} on $97\%$, $82\%$, $84\%$, $95\%$, $95\%$ of the benchmark instances.
Especially on \emph{VLSI} instances, \KaHyPar{MF} calculates significantly better partitions
than all other hypergraph partitioners (see \DAC~and \ISPD~in \autoref{fig:final_flow}).\\
\begin{figure}
\centering
\input{experiments/final_flow/fullset.tex} %
\caption{Min-Cut performance plots comparing \KaHyPar{MF} with \KaHyPar{CA} and
         other partitioners. Plots are explained in Section \ref{sec:methodology}.}
\label{fig:final_flow}
\end{figure} 
Table \ref{tbl:running_time} shows the running time of all partitioners for different benchmark
types. The running time of \KaHyPar{MF} is within a factor of $2$ slower than \KaHyPar{CA} and
is comparable to the running time of \hMetis{K} and \hMetis{R}. 
\begin{table}[ht!]
\renewcommand{\arraystretch}{1.15}
\centering
\begin{tabular}{c|*{7}{S[table-number-alignment = center,table-column-width=1.45cm]}}
\toprule
\multirow{2}{*}{Partitioner} & \multicolumn{7}{c}{Running Time $t[s]$} \\
\cmidrule{2-8}
 & \multicolumn{1}{c}{\ALL} & \multicolumn{1}{c}{\DAC} & \multicolumn{1}{c}{\ISPD} & \multicolumn{1}{c}{\Primal} & \multicolumn{1}{c}{\Literal} & \multicolumn{1}{c}{\Dual} & \multicolumn{1}{c}{\SPM}  \\
\midrule%
\csname @@input\endcsname experiments/final_flow/final_flow_running_time.tex 
\bottomrule
\end{tabular} 
\caption{Comparing the average running time of \KaHyPar{MF} with \KaHyPar{CA} and
         other hypergraph partitioners.}
\label{tbl:running_time} 
\end{table}
