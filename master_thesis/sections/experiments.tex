\subsection{Instances}

Our full benchmark set consists of $488$ hypergraphs. We choose our benchmarks 
from three different research areas. For VLSI design we use instances from
the \emph{ISPD98 VLSI Circuit Benchmark Suite} (\ISPD) \cite{alpert1998ispd98} and add more recent
instances of the \emph{DAC 2012 Routability-Driven Placement Contest} (\DAC) \cite{viswanathan2012dac}.
Further, we interprete the Sparse Matrix instances of the \emph{Florida Sparse Matrix 
collection} (\SPM) \cite{davis2011university} as hypergraphs using the row-net model \cite{catalyurek1999hypergraph}.
The rows of each matrix are treated as hyperedges and the columns are the vertices of
the hypergraph. Our last benchmark type are SAT formulas of the \emph{International SAT
Competition 2014} \cite{belov2014application}. A common interpretation of a SAT formula 
as hypergraph is to interprete the literals as vertices and each clause as a net (\Literal) \cite{papa2007hypergraph}.
Mann and Papp \cite{mann2014formula} suggested two other hypergraph representation of
SAT formulas, called \Primal~and \Dual. The \Primal~representation treats each variable
as vertex and each clause as hyperedge. The \Dual~representation treats each clause as
vertex and the variables induced nets containing all clauses where the corresponding
variable occurs. A statiscal summary of the different instance types is presented in
Table \ref{tbl:type_properties}. \\
We divide our full benchmark set in two smaller subsets. Our \emph{parameter tunning}
benchmark set consists of $25$ hypergraphs, $5$ of each instance type (except \DAC). Additionally,
we choose a benchmark subset of $165$ instances. On our general experiments we partition
each hypergraph into $k \in \{2,4,8,16,32,64,128\}$ blocks and use for each $k$ $10$ different
\emph{seeds} with $\epsilon = 3\%$.

\begin{table}
\renewcommand{\arraystretch}{1.15}
\centering
\begin{tabular}{r|cc}
\toprule
Instance-Type & Avg. $d(v)$ & Avg. $|e|$ \\
\midrule%
\csname @@input\endcsname experiments/flow_network/instance_type_properties.tex 
\bottomrule
\end{tabular}
\caption{Average hypernode degree and hyperedge size of the different benchmark types in
         our benchmark subset.}
\label{tbl:type_properties}
\end{table}

\subsection{System and Methodology}

\begin{enumerate}
\item Used Compiler + Flags
\item Configuration of \emph{hMetis} and \emph{PaToH}
\item Describe \emph{cuber} plots
\end{enumerate}


\subsection{Flow Algorithms and Networks}

In the first experiment we want examine the impact of our sparsifying techniques (see Section \ref{sec:opt_flow_network})
on the performance of our maximum flow algorithms \GoldbergTarjan~and \EdmondKarp. 
Therefore, we first take a look at the reduction of the number of nodes and edges on different benchmark types
when using $\ExpLawler$ (see Section \ref{sec:related_lawler}), $\ExpNodeDegree$ (see Section 
\ref{sec:degree_network}), $\ExpEdgeSize$ (see Section \ref{sec:edge_size_network})
and $\ExpHybrid$ (see Section \ref{sec:hybrid_network}) . Further, we
want to evaluate the performance of the two implemented maximum flow algorithms on these
networks. \\
We evaluate the performance of the different flow networks on flow problems with
$|V'| \in \{500,1000,5000,10000,25000\}$ hypernodes. The instances are generated by executing
\emph{KaHyPar} on our benchmark subset (\todo{ref to appendix}) for $k = 2$ and five different 
seeds. After a instance is bipartitioned, we generate flow problem instances
with the above mentioned sizes and execute each possible combination of flow algorithm and
network on it. \\
The benchmark instances can be splitted into $6$ different benchmark types. The properties of these instances
in terms of the average hypernode degree and average hyperedge size is shown in \autoref{tbl:type_properties}.
Remember, $\ExpEdgeSize$ should perform best on instances with a small average hyperedge size and
$\ExpNodeDegree$ should perform best on instances with a small average hypernode degree. Based on 
\autoref{tbl:type_properties}, $\ExpEdgeSize$ should significantly reduce the number of
nodes and edges on \Primal~and \Literal~instances and $\ExpNodeDegree$ on \Dual~instances in
comparison to a our baseline $\ExpLawler$. Also both should sparsify the resulting flow network
of \ISPD~and \DAC~instances. Further, we expect that $\ExpHybrid$ combines the advantages of
both networks and performs best on all bechmark instances.\\
\autoref{fig:node_edge_distribution}~shows the predicted behaviour for flow problems of size
$25000$ hypernodes. A point on the grid is the \emph{geometric mean} of the number of 
nodes resp. edges (in the flow network) of all intances for the corresponding benchmark type.
$\ExpHybrid$ reduces the number of nodes of nearly every benchmark type by at least a factor
of $2$, except on \SPM~instances. Another observation is that instances with a large average 
hypernode degree, like \Primal~or \Literal, yield to big flow problem instances and vice 
versa (see \Dual~instances).\\
\begin{figure}
\centering
\input{experiments/flow_network/node_edge_distribution.tex} %
\caption{Comparison of the number of nodes and edges on our flow networks for 
         flow problems of size $|V'| = 25000$ hypernodes on different benchmark types.
         The red dashed lines indicates $25000$ nodes.}
\label{fig:node_edge_distribution}
\end{figure} 
In \autoref{fig:max_flow_network_algo} we compare the performance of our flow algorithms on
different flow networks. The bars in the plot indicates speed ups relative to the flow algorithm
\EdmondKarp~on flow network $\ExpLawler$. The main observation is that \EdmondKarp~performs
better on small flow network instances and \GoldbergTarjan~on large flow network instances. For $|V'| \le 1000$
\EdmondKarp~is faster than \GoldbergTarjan~in most of the different bechmark types. For
$|V'| > 1000$ we can observe the opposite behaviour except for \DAC~and \Dual~instances. But the
resulting flow problems of these instances are still the smallest among all benchmark types
(see \autoref{fig:node_edge_distribution}). On the largest flow network instances \Primal~and
\Literal~for $|V'| = 25000$ \GoldbergTarjan~is up to a factor of $4$-$7$ faster than \EdmondKarp.
Further, both algorithms perform best on $\ExpHybrid$.
\begin{figure}
\centering
\input{experiments/flow_network/speed_up_flow_network.tex} %
\caption{Speed up of our flow algorithms and networks relative to \EdmondKarp~on
         $\ExpLawler$ for different instance sizes and types. The red dashed line indicates the
         $($\EdmondKarp$,\ExpLawler)$ implementation and the blue dashed line
         indicates a speed up by a factor of $2$.}
\label{fig:max_flow_network_algo}
\end{figure} 
\autoref{tbl:flow_algo_network_summary}~shows the summary of our flow algorithm and network experiment
on all benchmark instances. This proofs our assumption that \EdmondKarp~works best on small instances
and \GoldbergTarjan~on large instances. However, our \emph{Max-Flow-Min-Cut} computations
are embedded in a \emph{Adapative Flow Iteration} strategy (see Section \ref{sec:adaptive_flow_iterations}).
Therefore, the running time of flow instances generated with a large $\alpha$ will dominate the
ones with small $\alpha$. Therefore, we choose \GoldbergTarjan~in combination with our flow network
$\ExpHybrid$ in the following experiments.
\begin{table}
\renewcommand{\arraystretch}{1.15}
\centering
\begin{tabular}{lr|*{4}{r@{\hspace{3mm}}}|*{4}{r@{\hspace{3mm}}}}
\toprule
 \multirow{2}{*}{\rotatebox{90}{\footnotesize{Instance}}} & \quad\quad & \multicolumn{4}{c|}{\GoldbergTarjan} & \multicolumn{4}{c}{\EdmondKarp} \\
\cmidrule{3-10}
 &  & $\ExpHybrid$ & $\ExpEdgeSize$ & $\ExpNodeDegree$ & $\ExpLawler$ & $\ExpHybrid$ & $\ExpEdgeSize$ & $\ExpNodeDegree$ & $\ExpLawler$ \\
 & $|V'|$ &  \tiny{$t[ms]$} & \tiny{$t[\%]$} & \tiny{$t[\%]$} & \tiny{$t[\%]$} & \tiny{$t[\%]$} & \tiny{$t[\%]$} & \tiny{$t[\%]$} & \tiny{$t[\%]$}
\\\midrule%
\csname @@input\endcsname experiments/flow_network/flow_network_max_flow_summary_table.tex 
\bottomrule
\end{tabular}
\caption{Running time comparison of maximum flow algorithms on different flow networks.
         Note, all values in the table are in percentage relative to \GoldbergTarjan~
         on flow network $\ExpHybrid$. In each line the fastest variant is marked bold.}
\label{tbl:flow_algo_network_summary}
\end{table}

\subsection{Configuration of the $k$-way Flow-based Refiner}
\label{sec:flow_configuration}

In this Section we examine the quality of our $k$-way flow-based refinement algorithm with
different configurations on our parameter tuning benchmark subset (\todo{ref to appendix}).
There are several configurations and tunning parameters which we have to evaluate:
\begin{itemize}
\item \emph{Max-(F)low-Min-Cut} computations as refinement algorithm (see Section \ref{sec:flow_local_search_hypergraph})
\item \emph{Adaptive Flow Iteration} parameter $\alpha'$ (see Section \ref{sec:adaptive_flow_iterations})
\item \emph{(C)ut Border Hyperedges} as sources and sinks (see Section \ref{sec:source_and_sink})
\item \emph{(M)ost Balanced Minimum Cut} heuristic (see Section \ref{sec:mbmc_hypergraphs})
\item Combining \emph{Max-(F)low-Min-Cut} computations with \emph{(FM)} refinement
\end{itemize}
In the following we will denote a configuration e.g. with \FlowVariant{+}{-}{-}{-} which indicates
which heuristic resp. technique is enabled $(+)$ or disabled $(-)$. The meaning of the 
abbreviations are explained in the enumeration above (see letters inside parenthesis). We evaluate
a configuration for $k \in \{2,4,8,16,32,64,128\}$, $\alpha' \in \{1,2,4,8,16\}$
and $10$ different seeds on our parameter tuning benchmark subset ($\epsilon = 3\%$). 
Our pairwise flow-based refinement is embedded in a $k$-way \emph{Active Block Scheduling}
refinement which is executed on each level $i$ with $i = 2^j$ ($j \in \mathbb{N}_+$) 
(see Section \ref{sec:flow_local_search_hypergraph}). As reference we use the 
latest quality configuration of \emph{KaHyPar} \cite{heuer2017improving}. \\
The results are summarized in \autoref{tbl:alpha_exp}. The values
in the column \emph{Gmean} are improvements of the connectivity metric
relative to our baseline configuration \FlowVariant{-}{-}{-}{+}. The running
time are absolute values in seconds. The first observation is that flows on
its own as refinement strategy are not strong enough to outperform the
\emph{FM} heuristic. Our strongest configuration with $\alpha' = 16$
is $2.5\%$ worse than our \emph{FM} baseline. But the result 
is still remarkable, because we only execute flows on $\log{n}$ levels
instead on $n$ as the \emph{FM} algorithm do. The running time of
scales nearly linear with parameter $\alpha'$. Using our improved source 
and sink modelling approach with \emph{Cut Border Hyperedges} (see Equation
\ref{S_final_border_hyperedges} and \ref{T_final_border_hyperedges})
significantly improves the solution quality especially for small $\alpha'$.
For small $\alpha$ most of the hypernodes are either a source or a sink. 
Introducing \emph{Cut Border Hyperedges} reduces the number of hypernode
sources and sinks by adding hyperedge sources and sinks. The quality 
improvement with this technique is therefore more effective
for small $\alpha'$, because it significantly increase the possibilities
of moving hypernodes between the blocks compared to the source and sink set
modelling approach with Equation \ref{S_border_hyperedges} and \ref{T_border_hyperedges}.
The opposite effect can be observed, if we use the \emph{Most Balanced Minimum Cut} heuristic
without \emph{Cut Border Hyperedges}. The quality improvement is more significant for large
$\alpha'$. The larger the flow problem, the higher is the number of different minimum 
$(S,T)$-cutsets and this increases the possibility to find a feasible solution according to 
our balanced constraint. If we combine both techniques, we obtain a configuration which significantly
improves the solution quality for all $\alpha'$ compared to our baseline flow configuration.
Also it outperforms our baseline \emph{FM} configuration for $\alpha' = 16$ by $0.51\%$.
If we enable \emph{FM} refinement in all levels where no flow is executed, we improve the solution
quality by nearly $2\%$ (for $\alpha' = 16$). Also the running time of this variant is faster
than all previous flow configurations, because we transfer more work to the \emph{FM} refinement.
This has as consequence that a block becomes faster \emph{inactive} during \emph{Active Block 
Scheduling} and this decreases the number of rounds of complete pairwise flow-based refinements
on the quotient graph.

\begin{table}
\renewcommand{\arraystretch}{1.15}
\centering
\begin{tabular}{|r||c|c||c|c||c|c|}
\toprule
 Config. & \multicolumn{2}{c||}{\FlowVariant{+}{-}{-}{-}} & \multicolumn{2}{c||}{\FlowVariant{+}{+}{-}{-}}  & \multicolumn{2}{c|}{\FlowVariant{+}{-}{+}{-}} \\
\midrule
$\alpha'$ & Gmean$[\%]$ & $t[s]$ & Gmean$[\%]$ & $t[s]$ & Gmean$[\%]$ & $t[s]$ \\
\midrule%
\csname @@input\endcsname experiments/flow_alpha/flow_alpha_table1.tex 
\cmidrule[1.25pt]{1-5}%
 Config. & \multicolumn{2}{c||}{\FlowVariant{+}{+}{+}{-}} & \multicolumn{2}{c||}{\FlowVariant{+}{+}{+}{+}} \\
\cmidrule{1-5}
$\alpha'$ & Gmean$[\%]$ & $t[s]$ & Gmean$[\%]$ & $t[s]$ \\
\cmidrule{1-5}%
\csname @@input\endcsname experiments/flow_alpha/flow_alpha_table2.tex 
\cmidrule{1-5}
\end{tabular}
\caption{ Table contains results for different configurations of our flow algorithm with
          increasing $\alpha'$. }
\label{tbl:alpha_exp}
\end{table}

\todo{evaluate effectiveness of flows}

\subsection{Speed-Up Heuristics}

At the end of Section \ref{sec:flow_local_search_hypergraph} we present several heuristics
to prevent unnecessary flow executions during \emph{Active Block Scheduling} ((R1)-(R3)).
The main assumption is that only a minority of \emph{Max-Flow-Min-Cut} computations
lead to an improvement on $H$. To prove that we execute \KaHyPar{MF} on our benchmark subset
(\todo{ref to appendix}) and enable one heuristic after another.\\
Table \ref{tbl:heuristics} summarizes the results of the experiment. \KaHyPar{CA} is the currently
best configuration of \emph{KaHyPar} and \KaHyPar{MF} is our baseline flow configuration of
Section \ref{sec:flow_configuration}. The index of the remaining variants of \KaHyPar{MF} 
describes which speed-up heuristics are enabled (see Section \ref{sec:flow_local_search_hypergraph}).
The values inside the table are \emph{geometric means} over the corresponding metric. On average,
enabling all speed up heuristics worsen the quality of \KaHyPar{MF} only by $0.07\%$. On the other
hand the \emph{Max-Flow-Min-Cut} computations are significantly faster by a factor of $\approx 2$.
In its final configuration \KaHyParConfig{MF}{R1,R2,R3} computes partitions with $\approx 2\%$ better
quality ($(\lambda - 1)$-metric) than \KaHyPar{CA} by a slowdown only of a factor of $\approx 2$.
In the following we will denote our final configuration \KaHyParConfig{MF}{R1,R2,R3} with
\KaHyPar{MF}.

\begin{table}
\renewcommand{\arraystretch}{1.15}
\centering
\begin{tabular}{l|cccc}
\toprule
Variant & Avg.$[\%]$ & Min.$[\%]$ & $t_{\text{flow}}[s]$ & $t[s]$ \\
\midrule%
\csname @@input\endcsname experiments/speed_up_heuristics/heuristic_table.tex 
\bottomrule
\end{tabular} 
\caption{Table shows results for our flow algorithm with different speed up heuristics.}
\label{tbl:heuristics}
\end{table}

\subsection{Comparison against other Hypergraph Partitioner}

\begin{enumerate}
\item Compare final configuration of flow refiner against sea config on the full benchmark set
\end{enumerate}



