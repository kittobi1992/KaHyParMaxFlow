In this Section, we evaluate the performance of our flow-based refinement framework proposed
in Section \ref{sec:opt_flow_network} and \ref{sec:flow_refinement}. First, we show the
effect of the techniques to sparsify the Lawler-Network \cite{lawler1973} on the
performance of our maximum flow algorithms. Afterwards, we analyze how the maximum
flow problem size influence the solution quality of different configurations of
our framework. Finally, we compare the new version of \emph{KaHyPar} with
\emph{Max-Flow-Min-Cut} computations against other
state-of-the-art hypergraph partitioners on our full benchmark set.


\subsection{Instances}

Our full benchmark set consists of $488$ hypergraphs. We choose our benchmarks 
from three different research areas. For VLSI design we use instances from
the \emph{ISPD98 VLSI Circuit Benchmark Suite} (\ISPD) \cite{alpert1998ispd98} and add more recent
instances of the \emph{DAC 2012 Routability-Driven Placement Contest} (\DAC) \cite{viswanathan2012dac}.
Further, we interpret the Sparse Matrix instances of the \emph{Florida Sparse Matrix 
collection} (\SPM) \cite{davis2011university} as hypergraphs using the row-net model \cite{catalyurek1999hypergraph}.
The rows of each matrix are treated as hyperedges and the columns are the vertices of
the hypergraph. Our last benchmark type are SAT formulas of the \emph{International SAT
Competition 2014} \cite{belov2014application}. A common interpretation of a SAT formula 
as hypergraph is to interpret the literals as vertices and each clause as a net (\Literal) \cite{papa2007hypergraph}.
Mann and Papp \cite{mann2014formula} suggested two other hypergraph representation of
SAT formulas, called \Primal~and \Dual. The \Primal~representation treats each variable
as vertex and each clause as hyperedge. The \Dual~representation treats each clause as
vertex and the variables induced nets containing all clauses where the corresponding
variable occurs. A statistical summary of the different instance types is presented in
Table \ref{tbl:full_benchmark_set}. \\
We divide our full benchmark set into two smaller subsets. Our \emph{parameter tuning}
benchmark set consists of $25$ hypergraphs, $5$ of each instance type (except \DAC). Additionally,
we choose a benchmark subset of $165$ instances. On our general experiments we partition
each hypergraph into $k \in \{2,4,8,16,32,64,128\}$ blocks and use for each $k$ $10$ different
\emph{seeds} with $\epsilon = 3\%$.

\subsection{System and Methodology}
\label{sec:methodology}

Our experiments run on a single core of a machine consisting of two \emph{Intel Xeon E5-
2670 Octa-Core} processors clocked at $2.6$ GHz. The machine has $64$ GB main memory,
$20$ MB L$3$- and $8\times256$ KB L$2$-Cache. The code is written in C++ and compiled using
\lstinline{g++-5.2} with flags \lstinline{-O3 -mtune=nactive -march=native}. We refer to
our new implementation of \emph{KaHyPar} with \emph{(M)ax-(F)low-Min-Cut} computations 
as \KaHyPar{MF} and the latest configuration with \emph{(C)ommunity-(A)ware} coarsening as
\KaHyPar{CA}. \\
We compare \KaHyPar{MF} against the state-of-the-art hypergraph partitioner \emph{hMetis} 
\cite{karypis1999multilevel,karypis2000multilevel} and \emph{PaToH} \cite{catalyurek1999hypergraph}.
\emph{hMetis} provides a direct $k$-way (\hMetis{K}) and recursive bisection (\hMetis{R}) implementation.
Further, we also use the default configuration (\PaToH{D}) and quality preset (\PaToH{Q}) of
\emph{PaToH}. We configure \emph{hMetis} to optimize the \emph{sum-of-external-degree}-metric
(SOED) and calculate $(\lambda-1)(\Pi) = \text{SOED}(\Pi) - \text{cut}(\Pi)$. This is also
suggested by the authors of \emph{hMetis} \cite{karypis2000multilevel}. Further, we have
to adapt the imbalance definition of \hMetis{R}. An imbalance value of $5$ means that the weight
of each bisected block is allowed to be between $0.45 \cdot c(V)$ and $0.55 \cdot c(V)$.
To ensure that \hMetis{R} produces a valid $\epsilon$-balanced partition after $\log_2(k)$
bisections we have to adapt $\epsilon$ to
\[\epsilon' = 100 \cdot \Bigg( \left( (1 + \epsilon) \frac{\lceil \frac{c(V)}{k} \rceil}{c(V)} \right)^{\frac{1}{\log_2(k)}} - 0.5 \Bigg)\]
If we evaluate the performance of our hypergraph partitioner,
we first summarize the results by calculating the average (or minimum) of a specific metric
for the diffrent \emph{seeds} of a hypergraph instance partitioned into $k$ blocks. 
Afterwards, we calculate the \emph{geometric mean} of 
all instances to give each instance comparable influence on the final result. 
To compare the performance of different hypergraph partitioners more detailed 
we use performance plots introduced in \cite{schlag2016k}.
\todo{Change description of performance plots}
For each partitioner $P$ and instance $H$ we calculate the values $q_{H,P} := 1 - \text{best$_H$}/\text{algorithm$_{H,P}$}$ 
where $\text{best$_{H}$}$ is the best quality achieved by a partitioner for instance $H$ and
$\text{algorithm$_{H,P}$}$ refers to the quality achieved by partitioner $P$ for instance
$H$. Afterwards, we sort all values $q_{H,P}$ of a partitioner $P$ in decreasing order. For each
partitioner $P$ we plot the points $(H,q_{H,P})$. The faster the $q_{H,P}$ values intersect
the zero line the better the performance of a partitioner in comparison to the others. If a partition
of a partitioner $P$ is not $\epsilon$-balanced we set $q_{H,P} = 1 + \beta$ (with $\beta > 0$).

\subsection{Flow Algorithms and Networks}
\label{sec:exp_flow_network}

In the first experiment, we evaluate the effect of our techniques to sparsify
the state-of-the-art hypergraph flow network representation (see Section \ref{sec:opt_flow_network})
on the performance of our maximum flow algorithms \GoldbergTarjan~and \EdmondKarp. 
We refer to our different flow networks as $\ExpLawler$ (see Section \ref{sec:related_lawler}), $\ExpNodeDegree$ (see Section 
\ref{sec:degree_network}), $\ExpEdgeSize$ (see Section \ref{sec:edge_size_network})
and $\ExpHybrid$ (see Section \ref{sec:hybrid_network}). \\
We evaluate the performance of our maximum flow algorithms on flow problems with
$|V'| \in \{500,1000,5000,10000,25000\}$ hypernodes. The instances are generated by executing
\emph{KaHyPar} on our benchmark subset (see Table \ref{tbl:benchmark_subset}) for $k = 2$ and five different 
seeds. After an instance is bipartitioned, we generate flow problem instances
with the above-mentioned sizes and execute each possible combination of flow algorithm and
flow network on it. \\
The benchmark instances can be split into $6$ different benchmark types. The properties of the instances
regarding the average hypernode degree and average hyperedge size is shown in \autoref{tbl:benchmark_subset}.
Remember, $\ExpEdgeSize$ should perform best on instances with a small average hyperedge size and
$\ExpNodeDegree$ should perform best on instances with a low average hypernode degree. Based on 
\autoref{tbl:benchmark_subset}, $\ExpEdgeSize$ should significantly reduce the number of
nodes and edges on \Primal~and \Literal~instances and $\ExpNodeDegree$ on \Dual~instances in
comparison to our baseline $\ExpLawler$. Also both should sparsify the resulting flow network
of \ISPD~and \DAC~instances. Further, we expect that $\ExpHybrid$ combines the advantages of
both networks and performs best on all benchmark types.\\
\autoref{fig:node_edge_distribution}~shows the the number of nodes and edges
of the resulting flow networks for flow problems with $25000$ hypernodes.
$\ExpHybrid$ reduces the number of nodes of nearly each benchmark type 
by at least a factor of $2$, except on \SPM~instances. Moreover, instances 
with a large average hypernode degree, like \Primal~or \Literal, yields large flow problem 
instances and instances with a small average hypernode degree yields small flow problem
instances (see \Dual~instances).\\
\begin{figure}[ht!]
\centering
\input{experiments/flow_network/node_edge_distribution.tex} %
\caption{Comparison of the number of nodes and edges induced by flow problems 
         of size $|V'| = 25000$ on our flow network for different benchmark types.
         The red dashed lines indicates $25000$ nodes.}
\label{fig:node_edge_distribution}
\end{figure} 
In \autoref{fig:max_flow_network_algo} we compare the performance of our maximum flow algorithms on the
different flow networks. The bars in the plot indicates speed-ups relative to the flow algorithm
\EdmondKarp~on flow network $\ExpLawler$. The main observation is that \EdmondKarp~performs
best on small flow network instances and \GoldbergTarjan~on large flow network instances. For $|V'| \le 1000$
\EdmondKarp~is faster than \GoldbergTarjan~on most of the different benchmark types. For
$|V'| > 1000$ we can observe the opposite behavior except for \DAC~and \Dual~instances. But the
resulting flow problems of these instances induce still the small flow problems compared to e.g.,
\Primal~or \Literal. (see \autoref{fig:node_edge_distribution}). 
On the largest flow network instances \Primal~and \Literal~for $|V'| = 25000$ 
\GoldbergTarjan~is up to a factor of $4$-$7$ faster than \EdmondKarp.
Further, both algorithms perform best on $\ExpHybrid$.\\
\begin{figure}
\centering
\input{experiments/flow_network/speed_up_flow_network.tex} %
\caption{Speedup of our flow algorithms and networks relative to \EdmondKarp~on
         $\ExpLawler$ for different instance sizes and types. The red dashed line indicates the
         $($\EdmondKarp$,\ExpLawler)$ implementation and the blue dashed line
         indicates a speedup by a factor of $2$.}
\label{fig:max_flow_network_algo}
\end{figure} 
\autoref{tbl:flow_algo_network_summary}~shows the summary of our flow algorithm and flow network experiment. 
It proofs our assumption that \EdmondKarp~works best on small instances
and \GoldbergTarjan~on large instances. However, the flow problem sizes in our
\emph{flow}-based refinement algorithm are chosen adaptively and depend on the
\emph{adaptive flow iteration} parameter $\alpha$ (see Section \ref{sec:adaptive_flow_iterations}).
Therefore, the running time of flow instances generated with a large $\alpha$ will dominate the
ones with small $\alpha$. Thus, we choose \GoldbergTarjan~in combination with our flow network
$\ExpHybrid$ in the following experiments.
\begin{table}
\renewcommand{\arraystretch}{1.15}
\centering
\begin{tabular}{lr|*{4}{r@{\hspace{3mm}}}|*{4}{r@{\hspace{3mm}}}}
\toprule
 \multirow{2}{*}{\rotatebox{90}{\footnotesize{Instance}}} & \quad\quad & \multicolumn{4}{c|}{\GoldbergTarjan} & \multicolumn{4}{c}{\EdmondKarp} \\
\cmidrule{3-10}
 &  & $\ExpHybrid$ & $\ExpEdgeSize$ & $\ExpNodeDegree$ & $\ExpLawler$ & $\ExpHybrid$ & $\ExpEdgeSize$ & $\ExpNodeDegree$ & $\ExpLawler$ \\
 & $|V'|$ &  \tiny{$t[ms]$} & \tiny{$t[\%]$} & \tiny{$t[\%]$} & \tiny{$t[\%]$} & \tiny{$t[\%]$} & \tiny{$t[\%]$} & \tiny{$t[\%]$} & \tiny{$t[\%]$}
\\\midrule%
\csname @@input\endcsname experiments/flow_network/flow_network_max_flow_summary_table.tex 
\bottomrule
\end{tabular}
\caption{Running time comparison of maximum flow algorithms on different flow networks.
         Note, all values in the table are in percentage relative to \GoldbergTarjan~
         on flow network $\ExpHybrid$. In each line the fastest variant is marked bold.}
\label{tbl:flow_algo_network_summary}
\end{table}

\subsection{Setup of the direct $k$-way Flow-Based Refinement}
\label{sec:flow_configuration}

In this Section, we analyze the quality of our $k$-way flow-based refinement algorithm with
different configurations on our parameter tuning benchmark subset (see Table \ref{tbl:parameter_tunning_set}).
There are several configurations and tuning parameters which we have to evaluate:
\begin{itemize}
\item \emph{Max-(F)low-Min-Cut} computations as refinement algorithm (see Section \ref{sec:flow_local_search_hypergraph})
\item \emph{Adaptive Flow Iteration} parameter $\alpha'$ (see Section \ref{sec:adaptive_flow_iterations})
\item \emph{(M)ost Balanced Minimum Cut} heuristic (see Section \ref{sec:mbmc_hypergraphs})
\item Combining \emph{Max-(F)low-Min-Cut} computations with \emph{(FM)} refinement
\end{itemize}
In the following, we will denote a configuration e.g. with \FlowVariant{+}{-}{-} which indicates
which heuristic resp. technique is enabled $(+)$ or disabled $(-)$. The meaning of the 
abbreviations is explained in the enumeration above (see letters inside parentheses). We evaluate
a configuration for $k \in \{2,4,8,16,32,64,128\}$, $\alpha' \in \{1,2,4,8,16\}$
and $10$ different seeds on our parameter tuning benchmark subset ($\epsilon = 3\%$). 
We execute a \emph{flow}-based \emph{local search} 
on each level $i$ with $i = 2^j$ ($j \in \mathbb{N}_+$) 
(see Section \ref{sec:flow_local_search_hypergraph}). Additionally, we add configuration
\FlowVariant{+}{+}{+} with \emph{flow execution policy} $i = 128j$ ($j \in \mathbb{N}_+$). 
This configuration has an impracticable running time, but should provide a lower bound
of the solution quality achievable with \emph{Max-Flow-Min-Cut} computations in combination
with \emph{FM} refinement.
We refer to this variant as \Constant{128}. Further, we use the 
latest version of \emph{KaHyPar} as reference \cite{heuer2017improving}. We refer to this variant as 
\FlowVariant{-}{-}{+}. \\
The results are summarized in \autoref{tbl:alpha_exp}. The values
in the column \emph{Avg} are improvements of the connectivity metric
relative to our baseline configuration \FlowVariant{-}{-}{+}. The running
time are absolute values in seconds. The first observation is that flows on
its own as refinement strategy are not strong enough to outperform the
\emph{FM} heuristic. Our strongest configuration with $\alpha' = 16$
is $2.58\%$ worse than our \emph{FM} baseline. But the result 
is still remarkable because we only execute flows on $\log{n}$ levels
instead of $n$ as the \emph{FM} algorithm is executed. The running time
scales nearly linear with parameter $\alpha'$. \\
Enabling the \emph{Most Balanced Minimum Cut} heuristic significantly improves the
quality compared to the configuration \FlowVariant{+}{-}{-}.
But the quality improvements are more significant for large
$\alpha'$. The larger the flow problem size, the larger is the number of different minimum 
$(S,T)$-cutsets and this increases the possibility to find a feasible solution according to 
our balanced constraint. Also it outperforms our baseline \emph{FM} 
configuration for $\alpha' = 16$ by $0.51\%$.\\
If we enable \emph{FM} refinement in all levels where no flow is executed, we improve the solution
quality by nearly $2\%$ (for $\alpha' = 16$). Also, the running time of this variant is faster
than all previous flow configurations because we transfer more work to the \emph{FM} refinement.
It has as a consequence that a block becomes faster \emph{inactive} during the \emph{active block 
scheduling} algorithm and this decreases the number of rounds of complete pairwise 
flow-based refinements. \\
Finally, \Constant{128} gives us a lower bound of the quality
achievable with a combination of \emph{flow}-based and \emph{FM} refinement. Flows are executed 
in each $128$th level of the multilevel hierarchy. The quality is $2.44\%$ better than our
baseline configuration, but $\approx 100$ times slower. Compared to \FlowVariant{+}{+}{+} for 
$\alpha = 16$, \Constant{128} is only $0.57\%$ better and around $\approx 25$ times slower.\\
Our best configuration is \FlowVariant{+}{+}{+} with $\alpha' = 16$. It is also the most 
effective one (see Effectiveness Test in Appendix \ref{appendix:effectiveness_test}). For
further experiments, we refer to this variant as \KaHyPar{MF}.

\begin{table}
\renewcommand{\arraystretch}{1.15}
\centering
\begin{tabular}{|r||c|c||c|c||c|c|c|c|}
\toprule
 Config. & \multicolumn{2}{c||}{\FlowVariant{+}{-}{-}} & \multicolumn{2}{c||}{\FlowVariant{+}{+}{-}}  & \multicolumn{2}{c|}{\FlowVariant{+}{+}{+}} & \multicolumn{2}{c|}{\Constant{128}} \\
\midrule
$\alpha'$ & Avg.$[\%]$ & $t[s]$ & Avg.$[\%]$ & $t[s]$ & Avg.$[\%]$ & $t[s]$ & Avg.$[\%]$ & $t[s]$ \\
\midrule%
\csname @@input\endcsname experiments/flow_alpha/flow_alpha_table.tex 
\bottomrule
\end{tabular}
\caption{ Table contains results for different configurations of our flow-based refinement
          framework for increasing $\alpha'$. The quality in column \emph{Avg.} is relative
          to our baseline configuration without the usage of flows. }
\label{tbl:alpha_exp}
\end{table}


\subsection{Speed-Up Heuristics}
\label{sec:speed_up}

At the end of Section \ref{sec:flow_local_search_hypergraph}, we have presented several heuristics
to prevent \emph{unpromising} flow executions during the \emph{active block scheduling} refinement ((R1)-(R3)).
The main assumption is that only a minority of \emph{Max-Flow-Min-Cut} computations
lead to an improvement. To verify this assumption, 
we execute \KaHyPar{MF} in combination with different speed-up heuristics 
on our benchmark subset (see Table \ref{tbl:benchmark_subset}). \\
Table \ref{tbl:heuristics} summarizes the results of the experiment. \KaHyPar{CA} is the current
version of \emph{KaHyPar} and \KaHyPar{MF} is our current flow configuration of
Section \ref{sec:flow_configuration}. The indices of the different variants of \KaHyPar{MF} 
describes which speed-up heuristic is enabled (see Section \ref{sec:flow_local_search_hypergraph}).
On average, enabling all speed-up heuristics worsen the quality of \KaHyPar{MF} only by 
$0.09\%$. On the other hand, the framework is significantly faster 
by a factor of $\approx 2$. In its final configuration \KaHyParConfig{MF}{R1,R2,R3} computes 
partitions with $2\%$ better quality ($(\lambda - 1)$-metric) than \KaHyPar{CA}, while only
incurring a slowdown of a factor of $2$. In the following, we will denote our final 
configuration \KaHyParConfig{MF}{R1,R2,R3} with \KaHyPar{MF}.

\begin{table}[ht]
\renewcommand{\arraystretch}{1.15}
\centering
\begin{tabular}{l|cccc}
\toprule
Variant & Avg.$[\%]$ & Min.$[\%]$ & $t_{\text{flow}}[s]$ & $t[s]$ \\
\midrule%
\csname @@input\endcsname experiments/speed_up_heuristics/heuristic_table.tex 
\bottomrule
\end{tabular} 
\caption{Results of our flow-based refinement framework with different speedup heuristics.}
\label{tbl:heuristics}
\end{table}

\subsection{Comparison with other Hypergraph Partitioner}
\label{sec:final_comparison}

Finally, we compare our new approach \KaHyPar{MF} with different state-of-the-art hypergraph
partitioner on our full benchmark set. We excluded $194$ instances of $3416$ either because 
\PaToH{Q} could not allocate enough memory or other partitioners did not finish in time. The
excluded instances are shown in Table \ref{tbl:excluded}. \\
\autoref{fig:final_flow}~summarizes the results of the experiment. \KaHyPar{MF}
produce on $\approx 70\%$ of all benchmark instances the best partitions. It is followed by
\hMetis{R} ($14\%$), \hMetis{K} ($11\%$), \KaHyPar{CA} ($2.4\%$), 
\PaToH{Q} ($1.9\%$) and \PaToH{D} ($1.4\%$). Comparing \KaHyPar{MF} 
individually with each partitioner, \KaHyPar{MF} produces better partitions than \KaHyPar{CA},
\hMetis{R}, \hMetis{K}, \PaToH{Q}, \PaToH{Q} on $96\%$, $80\%$, $82\%$, $95\%$, $95\%$ of the benchmark instances.
Especially on \emph{VLSI} instances, \KaHyPar{MF} calculates significantly better partitions
than all other hypergraph partitioners (see \DAC~and \ISPD~in \autoref{fig:final_flow}).\\
\begin{figure}
\centering
\input{experiments/final_flow/fullset.tex} %
\caption{Min-Cut performance plots comparing \KaHyPar{MF} with \KaHyPar{CA} and
         other systems. Plots are explained in Section \ref{sec:methodology}.}
\label{fig:final_flow}
\end{figure} 
Table \ref{tbl:running_time} shows the running time of all partitioner for different benchmark
types. The running time of \KaHyPar{MF} is within a factor of $2$ slower than \KaHyPar{CA} and
is comparable to the running time of \hMetis{K}. 
\begin{table}[ht!]
\renewcommand{\arraystretch}{1.15}
\centering
\begin{tabular}{c|ccccccc}
\toprule
\multirow{2}{*}{Partitioner} & \multicolumn{7}{c}{Running Time $t[s]$} \\
\cmidrule{2-8}
 & \ALL & \DAC & \ISPD & \Primal & \Literal & \Dual & \SPM \\
\midrule%
\csname @@input\endcsname experiments/final_flow/final_flow_running_time.tex 
\bottomrule
\end{tabular} 
\caption{Comparing the average running time of \KaHyPar{MF} with \KaHyPar{CA} and
         other hypergraph partitioners.}
\label{tbl:running_time} 
\end{table}
