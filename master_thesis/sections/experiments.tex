\subsection{Flow Algorithms and Networks}

In the first experiment we want examine the impact of our sparsifying techniques (see Section \ref{sec:opt_flow_network})
on the performance of our maximum flow algorithms \GoldbergTarjan~and \EdmondKarp. 
Therefore, we first take a look at the reduction of the number of nodes and edges on different benchmark types
when using $\ExpLawler$ (see Section \ref{sec:related_lawler}), $\ExpNodeDegree$ (see Section 
\ref{sec:degree_network}), $\ExpEdgeSize$ (see Section \ref{sec:edge_size_network})
and $\ExpHybrid$ (see Section \ref{sec:hybrid_network}) . Further, we
want to evaluate the performance of the two implemented maximum flow algorithms on these
networks. \\
We evaluate the performance of the different flow networks on flow problems with
$|V'| \in \{500,1000,5000,10000,25000\}$ hypernodes. The instances are generated by executing
\emph{KaHyPar} on our benchmark subset (\todo{ref to appendix}) for $k = 2$ and five different 
seeds. After a instance is bipartitioned, we generate flow problem instances
with the above mentioned sizes and execute each possible combination of flow algorithm and
network on it. \\
The benchmark instances can be splitted into $6$ different benchmark types. The properties of these instances
in terms of the average hypernode degree and average hyperedge size is shown in \autoref{tbl:type_properties}.
Remember, $\ExpEdgeSize$ should perform best on instances with a small average hyperedge size and
$\ExpNodeDegree$ should perform best on instances with a small average hypernode degree. Based on 
\autoref{tbl:type_properties}, $\ExpEdgeSize$ should significantly reduce the number of
nodes and edges on \Primal~and \Literal~instances and $\ExpNodeDegree$ on \Dual~instances in
comparison to a our baseline $\ExpLawler$. Also both should sparsify the resulting flow network
of \ISPD~and \DAC~instances. Further, we expect that $\ExpHybrid$ combines the advantages of
both networks and performs best on all bechmark instances.\\
\begin{table}
\renewcommand{\arraystretch}{1.15}
\centering
\begin{tabular}{r|cc}
\toprule
Instance-Type & Avg. $d(v)$ & Avg. $|e|$ \\
\midrule%
\csname @@input\endcsname experiments/flow_network/instance_type_properties.tex 
\bottomrule
\end{tabular}
\caption{Average hypernode degree and hyperedge size of the different benchmark types in
         our benchmark subset.}
\label{tbl:type_properties}
\end{table}
\autoref{fig:node_edge_distribution}~shows the predicted behaviour for flow problems of size
$25000$ hypernodes. A point on the grid is the \emph{geometric mean} of the number of 
nodes resp. edges (in the flow network) of all intances for the corresponding benchmark type.
$\ExpHybrid$ reduces the number of nodes of nearly every benchmark type by at least a factor
of $2$, except on \SPM~instances. Another observation is that instances with a large average 
hypernode degree, like \Primal~or \Literal, yield to big flow problem instances and vice 
versa (see \Dual~instances).\\
\begin{figure}
\centering
\input{experiments/flow_network/node_edge_distribution.tex} %
\caption{Comparison of the number of nodes and edges on our flow networks for 
         flow problems of size $|V'| = 25000$ hypernodes on different benchmark types.
         The red dashed lines indicates $25000$ nodes.}
\label{fig:node_edge_distribution}
\end{figure} 
In \autoref{fig:max_flow_network_algo} we compare the performance of our flow algorithms on
different flow networks. The bars in the plot indicates speed ups relative to the flow algorithm
\EdmondKarp~on flow network $\ExpLawler$. The main observation is that \EdmondKarp~performs
better on small flow network instances and \GoldbergTarjan~on large flow network instances. For $|V'| \le 1000$
\EdmondKarp~is faster than \GoldbergTarjan~in most of the different bechmark types. For
$|V'| > 1000$ we can observe the opposite behaviour except for \DAC~and \Dual~instances. But the
resulting flow problems of these instances are still the smallest among all benchmark types
(see \autoref{fig:node_edge_distribution}). On the largest flow network instances \Primal~and
\Literal~for $|V'| = 25000$ \GoldbergTarjan~is up to a factor of $4$-$7$ faster than \EdmondKarp.
Further, both algorithms perform best on $\ExpHybrid$.
\begin{figure}
\centering
\input{experiments/flow_network/speed_up_flow_network.tex} %
\caption{Speed up of our flow algorithms and networks relative to \EdmondKarp~on
         $\ExpLawler$ for different instance sizes and types. The red dashed line indicates the
         $($\EdmondKarp$,\ExpLawler)$ implementation and the blue dashed line
         indicates a speed up by a factor of $2$.}
\label{fig:max_flow_network_algo}
\end{figure} 
\autoref{tbl:flow_algo_network_summary}~shows the summary of our flow algorithm and network experiment
on all benchmark instances. This proofs our assumption that \EdmondKarp~works best on small instances
and \GoldbergTarjan~on large instances. However, our \emph{Max-Flow-Min-Cut} computations
are embedded in a \emph{Adapative Flow Iteration} strategy (see Section \ref{sec:adaptive_flow_iterations}).
Therefore, the running time of flow instances generated with a large $\alpha$ will dominate the
ones with small $\alpha$. Therefore, we choose \GoldbergTarjan~in combination with our flow network
$\ExpHybrid$ in the following experiments.
\begin{table}
\renewcommand{\arraystretch}{1.15}
\centering
\begin{tabular}{lr|*{4}{r@{\hspace{3mm}}}|*{4}{r@{\hspace{3mm}}}}
\toprule
 \multirow{2}{*}{\rotatebox{90}{\footnotesize{Instance}}} & \quad\quad & \multicolumn{4}{c|}{\GoldbergTarjan} & \multicolumn{4}{c}{\EdmondKarp} \\
\cmidrule{3-10}
 &  & $\ExpHybrid$ & $\ExpEdgeSize$ & $\ExpNodeDegree$ & $\ExpLawler$ & $\ExpHybrid$ & $\ExpEdgeSize$ & $\ExpNodeDegree$ & $\ExpLawler$ \\
 & $|V'|$ &  \tiny{$t[ms]$} & \tiny{$t[\%]$} & \tiny{$t[\%]$} & \tiny{$t[\%]$} & \tiny{$t[\%]$} & \tiny{$t[\%]$} & \tiny{$t[\%]$} & \tiny{$t[\%]$}
\\\midrule%
\csname @@input\endcsname experiments/flow_network/flow_network_max_flow_summary_table.tex 
\bottomrule
\end{tabular}
\caption{Running time comparison of maximum flow algorithms on different flow networks.
         Note, all values in the table are in percentage relative to \GoldbergTarjan~
         on flow network $\ExpHybrid$. In each line the fastest variant is marked bold.}
\label{tbl:flow_algo_network_summary}
\end{table}

\subsection{Configuration of the $k$-way Flow-based Refiner}

In this Section we examine the quality of our $k$-way flow-based refinement algorithm with
different configurations on our parameter tuning benchmark subset (\todo{ref to appendix}).
There are several configurations and tunning parameters which we have to evaluate:
\begin{itemize}
\item \emph{Max-(F)low-Min-Cut} computations as refinement algorithm (see Section \ref{sec:flow_local_search_hypergraph})
\item \emph{Adaptive Flow Iteration} parameter $\alpha'$ (see Section \ref{sec:adaptive_flow_iterations})
\item \emph{(C)ut Border Hyperedges} as sources and sinks (see Section \ref{sec:source_and_sink})
\item \emph{(M)ost Balanced Minimum Cut} heuristic (see Section \ref{sec:mbmc_hypergraphs})
\item Combining \emph{Max-(F)low-Min-Cut} computations with \emph{(FM)} refinement
\end{itemize}
In the following we will denote a configuration e.g. with \FlowVariant{+}{-}{-}{-} which indicates
which heuristic resp. technique is enabled $(+)$ or disabled $(-)$. The meaning of the 
abbreviations are explained in the enumeration above (see letters inside parenthesis). We evaluate
a configuration for $k \in \{2,4,8,16,32,64,128\}$, $\alpha' \in \{1,2,4,8,16\}$
and $10$ different seeds on our parameter tuning benchmark subset ($\epsilon = 3\%$). 
Our pairwise flow-based refinement is embedded in a $k$-way \emph{Active Block Scheduling}
refinement which is executed on each level $i$ with $i = 2^j$ ($j \in \mathbb{N}_+$) 
(see Section \ref{sec:flow_local_search_hypergraph}). As reference we use the 
latest quality configuration of \emph{KaHyPar} \cite{heuer2017improving}. \\
The results are summarized in \autoref{tbl:alpha_exp}. The values
in the column \emph{Gmean} are improvements of the connectivity metric
relative to our baseline configuration \FlowVariant{-}{-}{-}{+}. The running
time are absolute values in seconds. The first observation is that flows on
its own as refinement strategy are not strong enough to outperform the
\emph{FM} heuristic. Our strongest configuration with $\alpha' = 16$
is $2.5\%$ worse than our \emph{FM} baseline. But the result 
is still remarkable, because we only execute flows on $\log{n}$ levels
instead on $n$ as the \emph{FM} algorithm do. The running time of
scales nearly linear with parameter $\alpha'$. Using our improved source 
and sink modelling approach with \emph{Cut Border Hyperedges} (see Equation
\ref{S_final_border_hyperedges} and \ref{T_final_border_hyperedges})
significantly improves the solution quality especially for small $\alpha'$.
For small $\alpha$ most of the hypernodes are either a source or a sink. 
Introducing \emph{Cut Border Hyperedges} reduces the number of hypernode
sources and sinks by adding hyperedge sources and sinks. The quality 
improvement with this technique is therefore more effective
for small $\alpha'$, because it significantly increase the possibilities
of moving hypernodes between the blocks compared to the source and sink set
modelling approach with Equation \ref{S_border_hyperedges} and \ref{T_border_hyperedges}.
The opposite effect can be observed, if we use the \emph{Most Balanced Minimum Cut} heuristic
without \emph{Cut Border Hyperedges}. The quality improvement is more significant for large
$\alpha'$. The larger the flow problem, the higher is the number of different minimum 
$(S,T)$-cutsets and this increases the possibility to find a feasible solution according to 
our balanced constraint. If we combine both techniques, we obtain a configuration which significantly
improves the solution quality for all $\alpha'$ compared to our baseline flow configuration.
Also it outperforms our baseline \emph{FM} configuration for $\alpha' = 16$ by $0.51\%$.
If we enable \emph{FM} refinement in all levels where no flow is executed, we improve the solution
quality by nearly $2\%$ (for $\alpha' = 16$). Also the running time of this variant is faster
than all previous flow configurations, because we transfer more work to the \emph{FM} refinement.
This has as consequence that a block becomes faster \emph{inactive} during \emph{Active Block 
Scheduling} and this decreases the number of rounds of complete pairwise flow-based refinements
on the quotient graph.

\begin{table}
\renewcommand{\arraystretch}{1.15}
\centering
\begin{tabular}{|r||c|c||c|c||c|c|}
\toprule
 Config. & \multicolumn{2}{c||}{\FlowVariant{+}{-}{-}{-}} & \multicolumn{2}{c||}{\FlowVariant{+}{+}{-}{-}}  & \multicolumn{2}{c|}{\FlowVariant{+}{-}{+}{-}} \\
\midrule
$\alpha'$ & Gmean$[\%]$ & $t[s]$ & Gmean$[\%]$ & $t[s]$ & Gmean$[\%]$ & $t[s]$ \\
\midrule%
\csname @@input\endcsname experiments/flow_alpha/flow_alpha_table1.tex 
\cmidrule[1.25pt]{1-5}%
 Config. & \multicolumn{2}{c||}{\FlowVariant{+}{+}{+}{-}} & \multicolumn{2}{c||}{\FlowVariant{+}{+}{+}{+}} \\
\cmidrule{1-5}
$\alpha'$ & Gmean$[\%]$ & $t[s]$ & Gmean$[\%]$ & $t[s]$ \\
\cmidrule{1-5}%
\csname @@input\endcsname experiments/flow_alpha/flow_alpha_table2.tex 
\cmidrule{1-5}
\end{tabular}
\caption{ Not final experiments still running }
\label{tbl:alpha_exp}
\end{table}

\todo{evaluate effectiveness of flows}

\subsection{Speed-Up Heuristics}

\begin{enumerate}
\item For all $k$ on the benchmark subset test variants:
\begin{enumerate}
\item Without any speed up heuristic
\item than add one heuristic and show quality is equal and time is less
\end{enumerate}
\item Show which quality is possible with \emph{constant} flow execution policy
\end{enumerate}

\subsection{Comparison against other Hypergraph Partitioner}

\begin{enumerate}
\item Compare final configuration of flow refiner against sea config on the full benchmark set
\end{enumerate}



