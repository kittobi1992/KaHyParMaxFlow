Hypergraphs are a generalization of graphs, where each (hyper)edge can connect 
more than two (hyper)nodes. The $k$-way hypergraph partitioning problem is to 
partition the vertices of a hypergraph into $k$ disjoint non-empty blocks such
that the size of each block satisfies a lower and upper bound, while we simultaneously 
want to minimize an objective function. \\
Classical application areas can be found in \emph{VLSI} design, parallelization of
the Sparse Matrix-Vector Product and simplifying \emph{SAT} formulas 
\cite{karypis1999multilevel, mann2014formula, papa2007hypergraph}. The goal 
in \emph{VLSI} design is to partition a circuit into smaller units such that
the wires between the gates are as short as possible \cite{bulucc2016recent}.
A wire can connect more than two gates, therefore a hypergraph models a circuit more
accurate than a graph. In \emph{SAT} solving hypergraph partitioning is used to
decompose a formula into smaller subformulas, which can be solved easier \cite{mann2014formula}.
An other interesting application area of hypergraph partitioning is \emph{Warehouse Planning}. 
A warehouse consists of several storage spaces where products can be placed. 
If a list of previous orders is available, we can interpret the products as 
vertices and the orders as hyperedges. If we partition the hypergraph 
into $k$ blocks, where $k$ is the number of storage spaces,
we can place products in the warehouse such that products are close to each other if
they are often ordered together.\\
Hypergraph partitioning is an NP-hard problem \cite{lengauer2012combinatorial} and
it is even NP-hard to find a good approximation \cite{bui1992finding}.
The most common heuristic used in state-of-the-art hypergraph partitioner is the
\emph{multilevel paradigm} \cite{catalyurek1999hypergraph, heuer2017improving, karypis1999multilevel}.
First, a sequence of smaller hypergraphs is calculated by contracting a set of hypernode pairs
in each step (\emph{coarsening phase}). If the hypergraph is small enough, we can use expensive
heuristics to \emph{initial partition} the hypergraph into $k$ blocks. Afterwards, the sequence
of smaller hypergraphs is \emph{uncontracted} in reverse order and, at each level, a 
\emph{local search} heuristic is used to improve the quality of the partition 
(\emph{refinement phase}). \\
There exist several \emph{local search} heuristics for improving a partition of a hypergraph,
but only the \emph{FM} algorithm leads to a practical performance of a multilevel hypergraph
partitioner for large benchmarks \cite{papa2007hypergraph}. In general, the \emph{FM}
heuristics maintains gain values (according to the objective function) of moving a node
from its current block to another block \cite{fiduccia1988linear}. A move is performed, 
if its gain value is maximum among all possible moves. The algorithm can be implemented 
in linear time. However, for large hyperedges the gain is often equal to $0$. E.g., if
the objective function is cut, then the gain of a pin is only greater than zero if it is the
last pin of a block in a hyperedge. There exist several approaches which try to take the
future gain of vertex into account \cite{krishnamurthy1984improved}, but they are also
limited in their ability to look ahead \cite{zhao2002effective}. Therefore, the algorithm
tends to find local optimal solutions. \\
Sanders and Schulz \cite{sanders2011engineering} successfully integrated a \emph{flow}-based refinement
algorithm in their multilevel graph partitioner. It is well known that a maximum $(s,t)$-flow
calculation yields to a minimum $(s,t)$-cutset on graphs \cite{ford1956maximal}. Their general
approach is to extract a subgraph around the cut and configure the source and sink sets
of the flow problem such that a maximum flow calculation on the subgraph leads to a 
smaller cut on the original graph. In combination with the \emph{FM} heuristic, their \emph{local
search} algorithm can find out of locally optimal solutions and produces
the best partitions for a wide range of graph partitioning benchmarks. 

\subsection{Problem Statement}

Currently, there are no competitive alternatives to the \emph{FM} heuristic as \emph{local search}
algorithm for a multilevel hypergraph partitioner. Sanders and Schulz \cite{sanders2011engineering}
showed that \emph{flow}-based approaches could be used in a multilevel graph partitioner to obtain
high-quality partitions. Their algorithm is a generic framework, which basic ideas can be
applied one-to-one on hypergraphs. However, several key challenges remain.\\
First, we have to find an appropriate way to model a hypergraph as flow network. Each maximum
$(s,t)$-flow on this model should induce a minimum $(s,t)$-cutset on the hypergraph.
Afterwards, the model should be used to improve the cut of a given bipartition by
executing a \emph{Max-Flow-Min-Cut} algorithm only on a subset of the hypernodes. \\
The framework should be integrated into the $n$-level hypergraph partitioner 
\emph{KaHyPar}. \emph{KaHyPar} is a multilevel hypergraph partitioner in its most extreme 
version that only contracts two vertices in one level of the multilevel hierarchy
\cite{akhremtsev2017engineering,heuer2017improving,schlag2016k}. Consequently, the 
\emph{local search} algorithm is called $n$ times during \emph{uncontraction}.
Therefore, the most challenging part is to implement the framework in such a way that we obtain
high-quality partitions and simultaneously ensure that the running time is within
a constant factor slower than the current version of \emph{KaHyPar}.

\subsection{Contributions}

We present several techniques to sparsify the state-of-the-art hypergraph flow network
modeling approach proposed by Lawler \cite{lawler1973}. Our experiments indicate that
maximum flow algorithms are up to a factor of $3$ faster with our new network. Further, 
we show how to configure a flow problem on a subhypergraph of $H$ such that a 
maximum $(S,T)$-flow yields a improved cut of a given bipartition. We choose $S$ and
$T$ in a way such that the cut of $H$ after a \emph{Max-Flow-Min-Cut} computation on a subhypergraph 
is calculable with the help of the amount of a maximum $(S,T)$-flow in constant time.
We integrate algorithmic ideas of \cite{sanders2011engineering} into 
\emph{KaHyPar} and show that \emph{flow}-based refinement in combination with the
\emph{FM} algorithm produces the best partitions on a majority of real world benchmarks
in comparison to other state-of-the-art hypergraph partitioners. 
In numbers, compared to $5$ different systems we achieve on $70\%$ 
of $3222$ benchmark instances the best-known partitions. In comparison to the 
latest version of \emph{KaHyPar}, our new approach produces solutions that are
$2\%$ better on average, while only incurring a slowdown by a factor of $2$.
Moreover, our partitioner has a comparable running time to the direct $k$-way
version of \emph{hMetis} and outperforms it on $82\%$ of the benchmark instances.

\subsection{Outline}

We first introduce necessary notations and summarize related work in Sections \ref{sec:preliminaries}
and \ref{sec:related_work}. Afterwards, we describe techniques to sparsify the flow network
proposed by Lawler \cite{lawler1973} in Section \ref{sec:opt_flow_network}. In Section
\ref{sec:flow_refinement} we present our source and sink set modeling
approach and describe the integration of our \emph{flow}-based refinement framework into
the $n$-level hypergraph partitioner \emph{KaHyPar}. The experimental evaluation of our algorithm
is presented in Section \ref{sec:experiments}. Section \ref{sec:conclusion} concludes this thesis.