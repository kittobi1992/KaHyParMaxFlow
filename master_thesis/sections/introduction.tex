Hypergraphs are a generalization of graphs, where each (hyper)edge can connect 
more than two (hyper)nodes. The $k$-way hypergraph partitioning problem is to 
partition the vertices of a hypergraph into $k$ disjoint non-empty blocks such
that the size of each block satisfies a lower and upper bound, while we simultaneously 
want to minimize an objective function. \\
Classical application areas can be found in \emph{VLSI} design, parallelization of
the Sparse Matrix-Vector Product and simplifying \emph{SAT} formulas 
\cite{karypis1999multilevel, mann2014formula, papa2007hypergraph}. The goal 
in \emph{VLSI} design is to partition a circuit into smaller units such that
the wires between the gates are as short as possible \cite{bulucc2016recent}.
A wire can connect more than two gates, therefore a hypergraph models a circuit more
accurate than a graph. In \emph{SAT} solving hypergraph partitioning is used to
decompose a formula into smaller subformulas, which can be solved easier \cite{mann2014formula}.
An other interesting application area of hypergraph partitioning is \emph{Warehouse Planning}. 
A warehouse consists of several storage spaces where products can be placed. 
If a list of previous orders is available, we can interpret the products as 
vertices and the orders as hyperedges. If we partition the hypergraph 
into $k$ blocks, where $k$ is the number of storage spaces,
we can place products in the warehouse such that products are close to each other if
they are often ordered together.\\
Hypergraph partitioning is an NP-hard problem \cite{lengauer2012combinatorial} and
it is even NP-hard to find a good approximation \cite{bui1992finding}.
The most common heuristic used in state-of-the-art hypergraph partitioner is the
\emph{multilevel paradigm} \cite{catalyurek1999hypergraph, heuer2017improving, karypis1999multilevel}.
First, a sequence of smaller hypergraphs is calculated by contracting a set of hypernode pairs
in each step (\emph{coarsening phase}). If the hypergraph is small enough, we can use expensive
heuristics to \emph{initial partition} the hypergraph into $k$ blocks. Afterwards, the sequence
of smaller hypergraphs is \emph{uncontracted} in reverse order and, at each level, a 
\emph{local search} heuristic is used to improve the quality of the partition 
(\emph{refinement phase}). \\
There exist several \emph{local search} heuristics for improving a partition of a hypergraph.
One algorithm used in most of the state-of-the-art multilevel hypergraph partitioner is
the \emph{Fiduccia-Mattheyses} heuristic (FM). In general, the \emph{FM}
maintains gain values (according to a objective function) of moving a node
from its current block to another block \cite{fiduccia1988linear}. A move is performed, 
if its gain value is maximum among all possible moves. The \emph{FM} heuristic is generally
intuitive, flexible in adapting to different optimization objectives, easy to implement and
relatively fast \cite{zhao2002effective}. However, a move is performed locally and greedily.
Consequently, the algorithm tends to find local optimal solution which quality heavily depends
on the initial partition \cite{dutt1997vlsi}. Therefore, multiple runs are needed to find
a solution close to the global optimum. The probability of finding a good approximation
of the global optimum significantly drops if we partition large hypergraphs \cite{dutt1997vlsi}. 
Further, a move of a node only influences the gain function if the state of an incident hyperedge
changes \emph{immediately} after a move. An example is a hyperedge where all of its
vertices are in the same block except of one. A move of that node contributes to the gain if
the objective is e.g., \emph{cut} (sum of the weights of hyperedges which contains vertices of more
than one block). Especially for large hyperedges, we often have to \emph{push} a sequence of nodes
in a certain direction such that a single move of a node finally contributes to the gain.
Therefore, the gain of most vertices is equal to zero in such cases and thus the \emph{FM} heuristic
becomes meaningless \cite{mann2014formula}. Krishnamurthy \cite{krishnamurthy1984improved}
points out that the quality in such situations highly depends on random choices made within
the algorithm. Therefore, he enhanced the \emph{FM} algorithm with a look-ahead scheme
such that in case of ties one can incoroperate \emph{future gains} into the decision \cite{krishnamurthy1984improved}.
However, the \emph{forecast} is limited by a predefined parameter. \\
It seems natural to utilize the well-known max-flow min-cut theorem \cite{ford1956maximal}
to find minimum cuts in complex networks. If we have two nodes $s$ and $t$ of a (hyper)graph
we can find a minimum $(s,t)$-cutset separating $s$ and $t$ in polynomial time \cite{edmonds1972theoretical,
ford1956maximal,goldberg1988new}. The algorithm is not \emph{move}-based and act \emph{globally}
Therefore, it overcomes the drawbacks of the \emph{FM} algorithm. However, it was overlooked for a long time because
it was perceived as computationally expensive and impractical for (hyper)graph partitioning
\cite{liu1998network}. Moreover, it was not clear how to obtain a \emph{balanced partition}
with \emph{Max-Flow-Min-Cut} computations in reasonable time. Yang and Wong \cite{yang1996balanced}
implements the first flow-based min-cut algorithm for balanced hypergraph bipartitioning.
They show how to transform a hypergraph into a flow network such that each minimum $(s,t)$-cutset
of the network is equal with a minimum $(s,t)$-cutset of the hypergraph. Further, they describe
an algorithm which finds a balanced bipartition within a practical running time. The algorithm
can be seen as an alternative approach to the \emph{multilevel paradigm}. Most of the
consecutive work \cite{liu1998network,patkar2004efficient} builds on top of the algorithm
rather than combining flow-based local search algorithms with the multilevel paradigm. Moreover,
a balanced $k$-way partition is only obtainable by applying the bipartitioning algorithm
recursively \cite{yang1996balanced}.\\
Sanders and Schulz \cite{sanders2011engineering} successfully integrated a \emph{flow}-based refinement
algorithm in their multilevel graph partitioner. The algorithm is also applicable to the more
complicated direct $k$-way partitioning case. In general, their basic approach is to 
extract a subgraph around the cut of a bipartition and configure the source and sink sets
of the flow problem such that a maximum flow calculation on the subgraph leads to a 
smaller cut on the original graph. They combine the strength of flow-based and \emph{FM}
\emph{local search} by executing both algorithms alternating throughout the multilevel hierarchy.
As a result their multilevel graph partitioner produces the best partitions for 
a wide range of graph partitioning benchmarks. 

\subsection{Problem Statement}

The promising results of the flow-based \emph{local search} algorithm in the multilevel graph 
partitioner of Sanders and Schulz \cite{sanders2011engineering} to obtain balanced $k$-way
partitions indicates that such approaches have a significant impact on the solution
quality. A hypergraph can also be modeled as flow network such that each maximum $(s,t)$-flow calculation yields
a minimum cutset on the hypergraph separating $s$ and $t$ \cite{lawler1973,yang1996balanced}.
In this work, we investigate the approach of integrating a flow-based \emph{local search}
algorithm into a multilevel hypergraph partitioner for balanced direct $k$-way partitioning.\\
Ihler and Wagner \cite{ihler1993modeling} show that there is no graph model with the same
number of nodes than the hypergraph in general such that the sum of the weights of each cut (hyper)edge
in the graph model and the hypergraph is equal. Therefore, the corresponding flow network of a hypergraph
can have significantly more nodes than the hypergraph. For a hypergraph $H = (V,E)$, the state-of-the-art flow network
transformation has exactly $|V| + 2|E|$ number of nodes \cite{lawler1973,yang1996balanced}.
The running time of a maximum flow algorithm highly depends on the problem size. Therefore,
it would be preferable to find techniques which sparsify the flow network of a hypergraph.
In the next step, the model should be used to improve the cut of a given bipartition 
by a \emph{Max-Flow-Min-Cut} computation. To make the approach applicable for large benchmarks
the flow problem should be build only on a subset of the hypernodes. The technique allows
us to control the size of the flow network and simultaneously the running time of the
algorithm. \\
The framework should be integrated into the $n$-level hypergraph partitioner 
\emph{KaHyPar}. \emph{KaHyPar} is a multilevel hypergraph partitioner in its most extreme 
version that only contracts two vertices in one level of the multilevel hierarchy
\cite{akhremtsev2017engineering,heuer2017improving,schlag2016k}. Consequently, the 
\emph{local search} algorithm is called $n$ times during \emph{uncontraction}.
Therefore, the most challenging part is to implement the framework in such a way that we obtain
high-quality partitions and simultaneously ensure that the running time is within
a constant factor slower than the current version of \emph{KaHyPar}.

\subsection{Contributions}

We present several techniques to sparsify the state-of-the-art hypergraph flow network
modeling approach proposed by Lawler \cite{lawler1973}. Our experiments indicate that
maximum flow algorithms are up to a factor of $3$ faster with our new network. Further, 
we show how to configure a flow problem on a subhypergraph of $H$ such that a 
maximum $(S,T)$-flow yields a improved cut of a given bipartition. We choose $S$ and
$T$ in a way such that the cut of $H$ after a \emph{Max-Flow-Min-Cut} computation on a subhypergraph 
is calculable with the help of the amount of a maximum $(S,T)$-flow in constant time.
We integrate algorithmic ideas of \cite{sanders2011engineering} into 
\emph{KaHyPar} and show that \emph{flow}-based refinement in combination with the
\emph{FM} algorithm produces the best partitions on a majority of real world benchmarks
in comparison to other state-of-the-art hypergraph partitioners. 
In numbers, compared to $5$ different systems we achieve on $70\%$ 
of $3222$ benchmark instances the best-known partitions. In comparison to the 
latest version of \emph{KaHyPar}, our new approach produces solutions that are
$2\%$ better on average, while only incurring a slowdown by a factor of $2$.
Moreover, our partitioner has a comparable running time to the direct $k$-way
partitioner of \emph{hMetis} and outperforms it on $82\%$ of the benchmark instances
with a $14.71\%$ better solution quality.

\subsection{Outline}

We first introduce necessary notations and summarize related work in Sections \ref{sec:preliminaries}
and \ref{sec:related_work}. Afterwards, we describe techniques to sparsify the flow network
proposed by Lawler \cite{lawler1973} in Section \ref{sec:opt_flow_network}. In Section
\ref{sec:flow_refinement} we present our source and sink set modeling
approach and describe the integration of our \emph{flow}-based refinement framework into
the $n$-level hypergraph partitioner \emph{KaHyPar}. The experimental evaluation of our algorithm
is presented in Section \ref{sec:experiments}. Section \ref{sec:conclusion} concludes this thesis.