Hypergraphs are a generalization of graphs, where each (hyper)edge can connect 
more than two (hyper)nodes. The $k$-way hypergraph partitioning problem is to 
partition the vertices of a hypergraph into $k$ disjoint non-empty blocks such
that the size of each block satisfies a lower and upper bound, while we simultaneously 
want to minimize an objective function. \\
Classical application areas can be found in \emph{VLSI} design, parallelization of
the \emph{Sparse Matrix-Vector Product} and simplifying \emph{SAT} formulas 
\cite{karypis1999multilevel, mann2014formula, papa2007hypergraph}. The goal 
in \emph{VLSI} design is to partition a circuit into smaller units such that
the wires between the gates are as short as possible \cite{bulucc2016recent}.
A wire can connect more than two gates, therefore a hypergraph models a circuit more
accurate than a graph. In \emph{SAT} solving hypergraph partitioning is used to
decompose a formula into smaller subformulas, which can be solved easier \cite{mann2014formula}.
Beneath the traditional application areas hypergraph partitioning can also be found
in more vivid areas like \emph{Warehouse Planning}. A warehouse consists of several
storage spaces where products can be placed. If a list of previous orders is available, 
we can interpret the products as vertices and the orders as hyperedges. If we
partition the hypergraph into $k$ blocks, where $k$ is the number of storage spaces,
we can place products in the warehouse such that products are close to each other if
they are often ordered together.\\
Hypergraph partitioning is an NP-hard problem \cite{lengauer2012combinatorial} and
it is even NP-hard to find a good approximation \cite{bui1992finding}.
The most common heuristic used in state-of-the-art hypergraph partitioner is the
\emph{multilevel paradigm} \cite{catalyurek1999hypergraph, heuer2017improving, karypis1999multilevel}.
First, a sequence of smaller hypergraphs is calculated by contracting a set of hypernode pairs
in each step (\emph{coarsening phase}). If the hypergraph is small enough, we can use expensive
heuristics to \emph{initial partition} the hypergraph into $k$ blocks. Afterwards, the sequence
of smaller hypergraphs is \emph{uncontracted} in reverse order and, at each level, a 
\emph{local search} heuristic is used to improve the quality of a partition 
(\emph{refinement phase}). \\
There exists several \emph{local search} heuristics for improving a partition of a hypergraph,
but only the \emph{FM} algorithm leads to a practical performance of a multilevel hypergraph
partitioner for large benchmarks \cite{papa2007hypergraph}. In general, the \emph{FM}
heuristics maintains gain values (according to the objective function) of moving a node
from its current block to another block \cite{fiduccia1988linear}. A move is performed, 
if its gain value is maximum among all possible moves. The algorithm can be implemented 
in linear time. The main disadvantage of the algorithm is its limited ability to lookahead
\cite{zhao2002effective}. E.g., it might be more beneficial to move a hypernode with 
a small gain because it will induce many good moves later. Therefore, the algorithm
tends to find locally optimal solutions. \\ 
Sanders and Schulz \cite{sanders2011engineering} successfully integrated a \emph{flow}-based refinement
algorithm in their multilevel graph partitioner. It is well known that a maximum $(s,t)$-flow
calculation yields to a minimum $(s,t)$-cutset on graphs \cite{ford1956maximal}. Their general
approach was to extract a subgraph around the cut and configure the source and sink sets
of the flow problem such that a maximum flow calculation on the subgraph leads to a 
smaller cut on the original graph. In combination with the \emph{FM} heuristic, their \emph{local
search} algorithm can find out of locally optimal solutions and produces
the best partitions for a wide range of graph partitioning benchmarks.

\subsection{Problem Statement}

Currently, there are no competitive alternatives to the \emph{FM} heuristic as \emph{local search}
algorithm for a multilevel hypergraph partitioner. Sanders and Schulz \cite{sanders2011engineering}
showed that \emph{flow}-based approaches could be used in a multilevel graph partitioner to obtain
high-quality partitions. Their algorithm is a generic framework, which basic ideas can be
applied one-to-one on hypergraphs. However, several key challenges remain.\\
First, we have to find an appropriate model of a hypergraph as flow network. Each maximum
$(s,t)$-flow on this model should induce a minimum $(s,t)$-cutset on the hypergraph.
Afterwards, the model should be used to improve the cut of a given bipartition by
executing a flow problem on a subset of the hypernodes. Therefore, the 
sources and sinks must be configured to satisfy the above-formulated constraint. \\
The framework should be integrated into the $n$-level hypergraph partitioner 
\emph{KaHyPar}. \emph{KaHyPar} is a multilevel hypergraph partitioner in its most extreme 
version by only contracting two vertices in one level of the multilevel hierarchy
\cite{akhremtsev2017engineering,heuer2017improving,schlag2016k}. In the \emph{refinement 
phase}, $n$-\emph{local searches} are instantiated. Therefore, the most challenging part is
to implement the framework in such a way that we obtain
high-quality partitions and simultaneously ensure that the performance reduction is within
a constant factor.

\subsection{Contributions}

We present several sparsifying techniques of the state-of-the-art hypergraph flow network
modeling approach proposed by Lawler \cite{lawler1973}. Our experiments indicate that
maximum flow algorithms are up to a factor of $3$ faster with our new network. Further, 
we show that the source and sink sets of the resulting flow network of a subhypergraph 
of an already partitioned hypergraph can be configured more flexible than on graphs. More 
precisely, applying the approach of Sanders and Schulz \cite{sanders2011engineering}
directly on hypergraphs results in a minimum $(S,T)$-cutset greater or equal as with
our new technique. We integrate the framework of \cite{sanders2011engineering} into 
\emph{KaHyPar} and show that \emph{flow}-based refinement in combination with the
\emph{FM} algorithm produces on a majority of a wide range of real-world
benchmarks the best-known partitions in comparison to other state-of-the-art hypergraph
partitioners. In numbers, compared to $5$ different systems we achieve on $70\%$ 
of $3222$ benchmark instances the best-known partitions. In comparison to the 
latest quality preset of \emph{KaHyPar} our new approach produces on average $2\%$ better 
partitions and is only slower by a factor of $2$.

\subsection{Outline}

We first introduce necessary notations and summarize related work in Section \ref{sec:preliminaries}
and \ref{sec:related_work}. Afterwards, we describe sparsifying techniques of the flow network
proposed by Lawler \cite{lawler1973} in Section \ref{sec:opt_flow_network}. In Section
\ref{sec:flow_refinement} we present our optimized source and sink set modeling
approach and describe the integration of our \emph{flow}-based refinement framework into
the $n$-level hypergraph partitioner \emph{KaHyPar}. The evaluation of our new flow network
proposed in Section \ref{sec:opt_flow_network} and framework proposed in Section 
\ref{sec:flow_refinement} is presented in Section \ref{sec:experiments}. 
Section \ref{sec:conclusion} concludes this thesis.