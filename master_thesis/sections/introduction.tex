Hypergraphs are a generalization of graphs where each (hyper)edge can connect 
more than two (hyper)nodes. The $k$-way hypergraph partitioning problem is to 
partition the vertices of a hypergraph into $k$ disjoint, non-empty blocks such
that the size of each block is smaller than $(1+\epsilon)$ times the
average block size, while simultaneousely minimizing an objective function on the hypergraph. \\
Classical application areas are in \emph{VLSI} design, parallelization of
the sparse matrix-vector multiplication and simplifying \emph{SAT} formulas 
\cite{karypis1999multilevel, mann2014formula, papa2007hypergraph}. The goal 
in \emph{VLSI} design is to partition a circuit into smaller units such that
the wires between the gates are as short as possible \cite{bulucc2016recent}.
A wire can connect more than two gates, therefore a hypergraph models a circuit more
accurately than a graph. In \emph{SAT} solving, hypergraph partitioning is used to
decompose a formula into smaller subformulas, which can be solved more easily \cite{mann2014formula}.\\
%Another interesting application area of hypergraph partitioning is \emph{Warehouse Planning}. 
%A warehouse consists of several storage spaces where products can be placed. 
%If a list of previous orders is available, we can interpret the products as 
%vertices and the orders as hyperedges. If we partition the hypergraph 
%into $k$ blocks, where $k$ is the number of storage spaces,
%we can place products in the warehouse such that products are close to each other if
%they are often ordered together.\\
Hypergraph partitioning is an NP-hard problem \cite{lengauer2012combinatorial} and
it is even NP-hard to find a good approximation \cite{bui1992finding}.
The most common heuristic used in state-of-the-art hypergraph partitioners is the
\emph{multilevel paradigm} \cite{catalyurek1999hypergraph, heuer2017improving, karypis1999multilevel}.
First, a sequence of smaller hypergraphs is generated by contracting matchings
or clusterings in each step (\emph{coarsening phase}). If the hypergraph is small enough, we can use expensive
heuristics to \emph{initially partition} it into $k$ blocks. Afterwards, the sequence
of smaller hypergraphs is \emph{uncontracted} in reverse order and, at each level, a 
local search heuristic is used to improve the quality of the partition 
(\emph{refinement phase}). \\
There exist several local search heuristics for improving hypergraph partitions.
Currently, variations of the \emph{FM} heuristic \cite{fiduccia1988linear} are used 
as local search algorithms in all state-of-the-art multilevel hypergraph partitioners.  
All such approaches have in common that they greedily move hypernodes 
between blocks of a partition according to an associated \emph{gain} value that 
depends on the local structure around a vertex. The \emph{FM} heuristic is generally
intuitive, easily adaptable to different optimization objectives and
relatively fast \cite{zhao2002effective}. \\
However, the gain of moving a hypernode to another block only depends on the state of the
incident hyperedges. Therefore, \emph{FM} has no \emph{global} view on the structure
of the problem. A move is performed \emph{locally} and \emph{greedily}.
Consequently, the algorithm tends to find locally optimal solutions, whose quality heavily depends
on the initial partition \cite{dutt1997vlsi}. 
%Therefore, multiple runs are needed to find
%a solution close to the global optimum. The probability of finding a good approximation
%of the global optimum significantly drops if we partition large hypergraphs \cite{dutt1997vlsi}.
If we execute \emph{FM} in the multilevel context, we partially solve the problem.
A move of a vertex in a coarsened hypergraph corresponds to a movement
of a subset of the hypernodes on the \emph{original} hypergraph, which allows a more 
effective exploration of the solution space \cite{papa2007hypergraph}. The quality of
the solution then depends more on the quality of the coarsening rather than
on the initial partition.\\
A move of a node only influences the gain function if the state of an incident hyperedge
changes \emph{immediately} after a move. If a hyperedge contains vertices from two different blocks,
where only one hypernode is contained in the first and all remaining hypernodes are in the second block,
then a move of that node contributes to the gain if the objective is e.g., \emph{cut} 
(sum of the weights of hyperedges which contain vertices of more than one block). 
Especially for large hyperedges, a sequence of nodes have to be moved
such that a single move of a node finally contributes to the gain.
Therefore, the gain of most vertices is equal to zero in such cases \cite{mann2014formula}. 
Krishnamurthy \cite{krishnamurthy1984improved} points out that the quality 
in such situations highly depends on random choices made within
the algorithm. Therefore, he enhanced the \emph{FM} algorithm with a look-ahead scheme
such that in case of ties one can incoroperate \emph{future gains} into the decision \cite{krishnamurthy1984improved}.
However, this \emph{forecast} is limited by a predefined parameter. \\
\emph{FM}-based local search algorithms have the above-mentioned disadvantages, because
they are move-based and only incoroperate local informations about the structure of the problem.
Finding a balanced global minimum cut of a (hyper)graph is NP-hard, but if we ask for a minimum
cut separating two vertices $s$ and $t$, the problem becomes solvable in polynomial time \cite{edmonds1972theoretical}.
The well-known \emph{max-flow min-cut} theorem \cite{ford1956maximal} relates the
maximum flow from a source $s$ to a sink $t$ to the minimum cut separating
$s$ and $t$ in a graph. \emph{Flow}-based approaches are not move-based and
incoroperate the \emph{global} structure of the problem.
Therefore, they overcome the drawbacks of the \emph{FM} algorithm. However, they were overlooked for a long time because
it was perceived as computationally expensive and impractical for (hyper)graph partitioning
\cite{liu1998network}. \\ 
Sanders and Schulz \cite{sanders2011engineering} successfully integrated a \emph{flow}-based refinement
algorithm into their multilevel \emph{graph} partitioner. 
%The algorithm is also applicable to the more
%complicated direct $k$-way partitioning case. 
%In general, their basic approach is to 
%extract a subgraph around the cut of a bipartition and configure the source and sink sets
%of the flow problem such that a maximum flow calculation on the subgraph leads to a 
%smaller cut on the original graph. 
They combine the strength of \emph{flow}-based refinement and \emph{FM}
local search by executing both algorithms alternating throughout the multilevel hierarchy.
As a result their multilevel graph partitioner produces the best partitions for 
a wide range of graph partitioning benchmarks. 
Recently, several algorithms were developed to obtain a balanced bipartition of a hypergraph 
with \emph{Max-Flow-Min-Cut} computations \cite{liu1998network,patkar2004efficient,yang1996balanced}. 
A balanced $k$-way hypergraph partition with such an approach is currently only
obtainable by applying the bipartitioning algorithm recursively \cite{yang1996balanced}. 
The impact of a \emph{flow}-based refinement algorithm on the solution quality of 
a multilevel hypergraph partitioner has not been studied yet. 

\subsection{Problem Statement}

Motivated by the results of Sanders and Schulz \cite{sanders2011engineering}, this thesis
integrates such an approach into the $n$-level hypergraph partitioner \emph{KaHyPar} \cite{heuer2017improving}.
One of the fundamental questions of this work is how \emph{Max-Flow-Min-Cut} computations
can be used to improve a given bipartition of hypergraphs. Therefore, the hypergraph
must be modeled as a flow network such that each minimum cut separating two vertices
$s$ and $t$ is computable with a maximum $(s,t)$-flow. The bipartitioning algorithm is 
the theorectical foundation for a framework to improve balanced $k$-way partitions of hypergraphs.
The last step is to integrate the framework into the
$n$-level hypergraph partitioner \emph{KaHyPar} \cite{heuer2017improving} and evaluate
the performance on a large benchmark set in comparison to different state-of-the-art 
multilevel hypergraph partitioners. A major goal of this work is to outperform the 
latest version of \emph{KaHyPar} on most of the benchmark instances and simultaneousely
ensure that the running time remaining competitive.

\subsection{Contributions}

We present several techniques to sparsify the hypergraph flow network
representation proposed by Lawler \cite{lawler1973}. Our experiments indicate that
maximum flow algorithms are up to a factor of $2$ faster on our new networks. 
%The theorectical results, which leads to the presented sparsification techniques, are
%of independent interest and can also be applied on general flow networks.
Our \emph{Max-Flow-Min-Cut} refinement framework is inspired by algorithmic ideas of
Sanders and Schulz \cite{sanders2011engineering}. However, we generalize many results of
their work such that they are applicable to hypergraph partitioning. We show how to 
configure a flow problem on a subhypergraph such that a 
maximum $(S,T)$-flow improves a given bipartition. 
Further, we show theoretically and practically that with our modeling approach 
better minimum cuts are achievable compared to the results of Sanders and Schulz.
Additionally, we implement several heuristics to prevent unpromising \emph{Max-Flow-Min-Cut} computations 
throughout the multilevel hierarchy and show that they speed-up the framework by factor
of $2$ while maintaining the solution quality.
We integrate our \emph{flow}-based refinement algorithm into the $n$-level hypergraph partitioner
\emph{KaHyPar} and show that the combination of \emph{flow}-based refinement and
\emph{FM} algorithm produces the best partitions on a majority of real world benchmarks
in comparison to other state-of-the-art hypergraph partitioners. 
Compared to $5$ different systems, we achieve the best partitions on $73\%$ 
of $3216$ benchmark instances. In comparison to the 
latest version of \emph{KaHyPar}, our new approach improves quality by
$2.5\%$ on average, while only incurring a slowdown by a factor of $2$.
However, our algorithm is still as fast the direct $k$-way
version of \emph{hMetis} and outperforms it on $84\%$ of the benchmark instances

\subsection{Outline}

We first introduce necessary notations and summarize related work in Sections \ref{sec:preliminaries}
and \ref{sec:related_work}. Afterwards, we describe techniques to sparsify the flow network
proposed by Lawler \cite{lawler1973} in Section \ref{sec:opt_flow_network}. In Section
\ref{sec:flow_refinement} we present our source and sink set modeling
approach and describe the integration of our \emph{flow}-based refinement framework into
the $n$-level hypergraph partitioner \emph{KaHyPar}. The experimental evaluation of our algorithm
is presented in Section \ref{sec:experiments}. Section \ref{sec:conclusion} concludes this thesis.