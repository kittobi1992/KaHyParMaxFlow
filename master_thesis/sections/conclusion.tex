In this thesis, we present a novel refinement algorithm based on \emph{Max-Flow-Min-Cut}
computations for multilevel hypergraph partitioning. We integrate our framework
into the $n$-level hypergraph partitioner \emph{KaHyPar} and show that
in combination with the \emph{FM} algorithm our new approach produces the best partitions
for a wide range of applications.\\
We introduce several techniques to 
sparsify the standard hypergraph flow network \cite{lawler1973},
which consists of many edges with \emph{infinite} capacity. We present
several theoretical results, which allows us to remove such edges or even to remove
nodes. The results are of independent interest, because they are also
applicable on general flow networks with \emph{infinite} capacity edges.
The main practical implications are that we can remove any hypernode 
from the hypergraph flow network and model hyperedges of size $2$ more efficiently. 
Our final flow network combines the two techniques, which reduces 
the problem size of the resulting flow networks on various benchmark types by up to 
a factor of $2$ compared to the state-of-the-art representation and
simultanousely speed-up the running time of different maximum flow algorithms 
by the same amount.  \\
Our \emph{flow}-based refinement framework is based on ideas of Sanders and Schulz
\cite{sanders2011engineering} (developed for multilevel graph partitioning). However,
we generalize many results such that they are applicable to hypergraph partitioning.
We configure a flow problem on a subhypergraph in such a way that a \emph{Max-Flow-Min-Cut}
computation improves a given bipartition of a hypergraph. Further, we show theoretically
and practically that with our modeling approach better minimum cuts are achievable
compared to the results of Sanders and Schulz. The bipartitioning algorithm is transferred
to the direct $k$-way partitioning case by executing pairwise \emph{flow}-based refinements
on two adjacent blocks according to the \emph{active block scheduling} strategy \cite{holtgrewe2010engineering}.
We integrate the framework into the $n$-level hypergraph partitioner \emph{KaHyPar}.
The total number of \emph{flow}-based refinements throughout the multilevel hierarchy
is controlled by a \emph{flow execution policy}. In each level, where no \emph{flow}
is execeuted, the \emph{FM} algorithm is used to improve the partition. Additionally,
we develop several heuristics to prevent \emph{unpromising} \emph{Max-Flow-Min-Cut}
computations on two adjacent blocks, which speed-up our framework
by a factor of $2$. \\
The new configuration \KaHyPar{MF} produces on $95\%$ of our benchmark instances
better partitions than our old configuration \KaHyPar{CA}. On average the solution 
quality is $2.4\%$ better, while only incurring a slowdown by a factor of $2$. 
In comparison with $5$ different state-of-the-art hypergraph partitioners, \KaHyPar{MF} 
produces on $70\%$ of $3222$ benchmark instances the best partitions. 
Moreover, our partitioner has a comparable running time to the direct $k$-way
version of \emph{hMetis} and outperforms it on $82\%$ of the benchmark instances.


\subsection{Future Work}

Due to the novelty of the approach, there is a lot of potential in optimizing our basic 
framework. We made a trade-off between time and quality to obtain a \emph{High-Quality 
n-level Hypergraph Partitioner} which runs in reasonable time. The quality mainly depends
on the number of flow executions throughout the multilevel hierarchy. The number of flow
executions, which we can do in reasonable time, depends on the running time of the 
flow algorithm and the size of the flow problem. Optimizing those two basic building 
blocks of the framework will allow us to achieve better quality in the same amount of time.\\
The flow network of a hypergraph proposed by Lawler \cite{lawler1973} has a bipartite 
structure. Because of this structural regularity, there might be other more specialized
flow algorithms which run faster on these types of networks. Therefore, a useful work 
would be to evaluate many different maximum flow algorithms on our benchmark set. Further,
one could investigate if it is possible to maintain the whole flow network over the
multilevel hierarchy without explicitly setting up the flow network before each flow
execution. Also, it would be interesting if information from previous flow calculations can 
be used to speed-up the current flow calculation. Pistorius \cite{pistorius2003} described
an algorithm which implicitly executes \EdmondKarp~on a hypergraph using
labels on the hypernodes. In our first version of the framework, we also used a similar 
technique and implicitly executes a flow algorithm on an implicit representation of 
the underlying network. During experiments, it turned out that the explicit representation
was up to a factor of $2$-$3$ faster than the implicit version. We encountered several reasons
for that behavior: 
\begin{enumerate}
\item Our flow network represents a subhypergraph of the original hypergraph. Iterating 
      over the edges of a node means to iterate also over hypernodes which are not part of 
      the flow problem and therefore have to be ignored.
\item There are many different cases when we want to increase the flow along an 
      \emph{augmenting path}.
\item Many labels have to be introduced which lead to a large number of 
      main memory accesses.
\item Also the implicit flow network is not flexible enough. Developing a new 
      technique to sparsify the flow networ would require a new implementation of 
      the implicit flow network.
\end{enumerate}
In Section \ref{sec:flow_local_search_hypergraph} and \ref{sec:speed_up} we show that with
three simple speed up heuristics our \emph{flow}-based refinement framework is up to a factor
of $2$ faster with comparable quality. Therefore, it would be beneficial to further increase
the effectiveness ratio of the flow computation by introducing more heuristics. \\
It is also possible to further sparsify the flow network. Assume there exists two hypernodes
$v_1$ and $v_2$ with $d(v_1) = 3$ and $d(v_2) = 4$. Further, $|I(v_1) \cap I(v_2)| = 3$ which means
that in each hyperedge $e$ where $v_1 \in e$ also $v_2 \in e$ except for one hyperedge $e'$
where $v_2 \in e'$ and $v_1 \notin e'$. We remove all hypernodes with $d(v) \le 3$ in our
\emph{hybrid} flow network. Consequently, we would remove $v_1$ and insert a clique between all incident
hyperedges. However, $v_2$ is part of the flow network and induce $2d(v_2) = 8$ edges because $d(v_2) > 3$.
Alternatively, we can remove $v_2$ and expand the clique between all hyperedges of $I(v_1)$
with $e'$. In that case, we have to insert an edge from each hyperedge in $I(v_1)$ to $e'$ and vice
versa. Since $|I(v_1)| = d(v_1) = 3$ only $2|I(v_1)| = 6$ edges are inserted and we can remove
one hypernode. In general, an expansion of a $k$-clique to a $(k+i)$-clique induced 
$ik$ edges from the $k$ nodes already contained in the clique to the $i$ new nodes and
$i(k+1-1)$ edges from the $i$ new nodes to the $k$ nodes in the clique. If we can remove a 
hypernode from the flow network by expanding a $k$-clique between hyperedge nodes to a $(k+i)$-clique,
it is beneficial if the following inequality holds 
\[ik + i(k+i-1) = i^2 + 2ki - i \le 2(k+i)\]
The inequality is only satisfied for $i = 1$. In this case, we can exactly remove $2$ edges and
$1$ node from the flow network. A possible algorithm could be to sort the hypernodes according
to the degree and for each hypernode store a clique label which indicates between how many
incident hyperedges already exist a clique. Afterwards, we iterate over the hypernodes and if we remove
a hypernode, we have to update the clique label of all hypernodes in the intersection of the
currently inserted clique. We iterate over the hypernodes until none of the hypernodes could
be removed anymore. However, we didn't find an efficient implementation of the above-described
algorithm. The algorithm requires a fast calculation between the intersection of several
hyperedges. An explicit construction of the intersection hypergraph would occupy too much
memory. 
