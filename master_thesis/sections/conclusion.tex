In this thesis, we present a novel refinement algorithm based on \emph{Max-Flow-Min-Cut}
computations for multilevel hypergraph partitioning. We integrate our framework
into the $n$-level hypergraph partitioner \emph{KaHyPar} and show that
in combination with the \emph{FM} algorithm our new approach produces the best partitions
for a wide range of applications.\\
We introduce several techniques to 
sparsify the standard hypergraph flow network \cite{lawler1973},
which consists of many edges with \emph{infinite} capacity. We present
several theoretical results, which allows us to remove such edges or even to remove
nodes. The results are of independent interest, because they are also
applicable on general flow networks with \emph{infinite} capacity edges.
The main practical implications are that we can remove any hypernode 
from the hypergraph flow network and model hyperedges of size $2$ more efficiently. 
Our final flow network combines the two techniques, which reduces 
the problem size of the resulting flow networks on various benchmark types by up to 
a factor of $2$ compared to the state-of-the-art representation and
simultanousely speed-up the running time of different maximum flow algorithms 
by the same amount.  \\
Our \emph{flow}-based refinement framework is based on ideas of Sanders and Schulz
\cite{sanders2011engineering} (developed for multilevel graph partitioning). However,
we generalize many results such that they are applicable to hypergraph partitioning.
We configure a flow problem on a subhypergraph in such a way that a \emph{Max-Flow-Min-Cut}
computation improves a given bipartition of a hypergraph. Further, we show theoretically
and practically that with our modeling approach better minimum cuts are achievable
compared to the results of Sanders and Schulz. The bipartitioning algorithm is transferred
to the direct $k$-way partitioning case by executing pairwise \emph{flow}-based refinements
on two adjacent blocks according to the \emph{active block scheduling} strategy \cite{holtgrewe2010engineering}.
We integrate the framework into the $n$-level hypergraph partitioner \emph{KaHyPar}.
The total number of \emph{flow}-based refinements throughout the multilevel hierarchy
is controlled by a \emph{flow execution policy}. In each level, where no \emph{flow}
is execeuted, the \emph{FM} algorithm is used to improve the partition. Additionally,
we develop several heuristics to prevent \emph{unpromising} \emph{Max-Flow-Min-Cut}
computations on two adjacent blocks, which speed-up our framework
by a factor of $2$. \\
The new configuration \KaHyPar{MF} produces on $97\%$ of our benchmark instances
better partitions than our old configuration \KaHyPar{CA}. On average the solution 
quality is $2.5\%$ better, while only incurring a slowdown by a factor of $2$. 
In comparison with $5$ different state-of-the-art hypergraph partitioners, \KaHyPar{MF} 
produces on $73\%$ of $3216$ benchmark instances the best partitions. 
Moreover, our partitioner has a comparable running time to the direct $k$-way
version of \emph{hMetis} and outperforms it on $84\%$ of the benchmark instances.


\subsection{Future Work}

The quality of our framework mainly depends on the number of flow executions
throughout the multilevel hierarchy and the running time of our maximum flow algorithms.
Optimizing those two basic building blocks of the framework will allow us to achieve 
better quality in the same amount of time.\\
The hypergraph flow network proposed by Lawler \cite{lawler1973} has a bipartite 
structure. Because of this structural regularity, there might be other more specialized
flow algorithms which run faster on these types of networks. Further,
one could investigate if it is possible to maintain the whole flow network over the
multilevel hierarchy instead of explicitly creating the flow network before each flow
execution. Also, it would be interesting if information from previous flow calculations can 
be used to speed-up the current flow calculation. Currently, it is possible to add edges and nodes to a flow network and speed-up
the flow computation by using informations of previous runs \cite{goldberg2015faster}. This 
would be an useful extension of the \emph{adaptive flow iteration} strategy, where we solve
a sequence of similar flow problems around the cut of two blocks of a partition. \\
Pistorius \cite{pistorius2003} describes an algorithm which implicitly 
executes \EdmondKarp~on hypergraphs using labels on the hypernodes. 
In our first version of the framework, we used a similar 
technique and implicitly executes a flow algorithm on an implicit representation of 
the underlying network. During initial experiments, it turned out that the explicit representation
was up to a factor of $2$-$3$ faster than the implicit version. 
This is due to the fact that our flow network represents a subhypergraph of the 
original hypergraph. Iterating over the edges of a node means to iterate also 
over hypernodes which are not part of the flow problem and therefore have to be ignored.
Further, many labels have to be introduced which lead to a large number of 
main memory accesses. Also the implicit flow network is not flexible enough. Developing a new 
technique to sparsify the flow network would require a new implementation of 
the implicit flow network.\\
Our current framework optimizes the \emph{connectivity} metric of a $k$-way partition.
It turned out that it is relatively simply to adapt the algorithm to different objective
functions. If we want to improve the \emph{cut} metric of a $k$-way partition with a 
\emph{Max-Flow-Min-Cut} computation on two adjacent blocks $V_i$ and $V_j$, we only have to extend the
source and sink set of the resulting flow problem with additional nodes. More precisely,
if a hyperedge contains a block $V_k$ with $V_k \notin \{V_i,V_j\}$, we add the
\emph{incoming} and \emph{outgoing} hyperedge node to the source and sink set (without a proof).
If we want to optimize \emph{sum of external degree} metric, we can use the same source and
sink set as for the \emph{connectivity metric} and double the capacity of each hyperedge $e$
with $\lambda(e,\Pi) \le 2$ (without a proof). In future versions of the framework, we want to
generalize our observations such that it can optimize any objective function, which value depends
on the \emph{connectivity} of a hyperedge.

%It is also possible to further sparsify the flow network. Assume there exists two hypernodes
%$v_1$ and $v_2$ with $d(v_1) = 3$ and $d(v_2) = 4$. Further, $|I(v_1) \cap I(v_2)| = 3$ which means
%that in each hyperedge $e$ where $v_1 \in e$ also $v_2 \in e$ except for one hyperedge $e'$
%where $v_2 \in e'$ and $v_1 \notin e'$. We remove all hypernodes with $d(v) \le 3$ in our
%\emph{hybrid} flow network. Consequently, we would remove $v_1$ and insert a clique between all incident
%hyperedges. However, $v_2$ is part of the flow network and induce $2d(v_2) = 8$ edges because $d(v_2) > 3$.
%Alternatively, we can remove $v_2$ and expand the clique between all hyperedges of $I(v_1)$
%with $e'$. In that case, we have to insert an edge from each hyperedge in $I(v_1)$ to $e'$ and vice
%versa. Since $|I(v_1)| = d(v_1) = 3$ only $2|I(v_1)| = 6$ edges are inserted and we can remove
%one hypernode. In general, an expansion of a $k$-clique to a $(k+i)$-clique induced 
%$ik$ edges from the $k$ nodes already contained in the clique to the $i$ new nodes and
%$i(k+1-1)$ edges from the $i$ new nodes to the $k$ nodes in the clique. If we can remove a 
%hypernode from the flow network by expanding a $k$-clique between hyperedge nodes to a $(k+i)$-clique,
%it is beneficial if the following inequality holds 
%\[ik + i(k+i-1) = i^2 + 2ki - i \le 2(k+i)\]
%The inequality is only satisfied for $i = 1$. In this case, we can exactly remove $2$ edges and
%$1$ node from the flow network. A possible algorithm could be to sort the hypernodes according
%to the degree and for each hypernode store a clique label which indicates between how many
%incident hyperedges already exist a clique. Afterwards, we iterate over the hypernodes and if we remove
%a hypernode, we have to update the clique label of all hypernodes in the intersection of the
%currently inserted clique. We iterate over the hypernodes until none of the hypernodes could
%be removed anymore. However, we didn't find an efficient implementation of the above-described
%algorithm. The algorithm requires a fast calculation between the intersection of several
%hyperedges. An explicit construction of the intersection hypergraph would occupy too much
%memory. 
